{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"},{"sourceId":7187809,"sourceType":"datasetVersion","datasetId":4116340},{"sourceId":9998059,"sourceType":"datasetVersion","datasetId":6152584},{"sourceId":176197,"sourceType":"modelInstanceVersion","modelInstanceId":150021,"modelId":172511}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":4494.775626,"end_time":"2024-11-22T09:13:14.476654","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-22T07:58:19.701028","version":"2.4.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Libraries","metadata":{"papermill":{"duration":0.006294,"end_time":"2024-11-22T07:58:22.754722","exception":false,"start_time":"2024-11-22T07:58:22.748428","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# %pip install -q torchsummary\n# %pip install -q torchgeometry\n%pip install -q segmentation-models-pytorch\n# %pip install -q timm","metadata":{"papermill":{"duration":33.69448,"end_time":"2024-11-22T07:58:56.455215","exception":false,"start_time":"2024-11-22T07:58:22.760735","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:26:44.637467Z","iopub.execute_input":"2024-11-24T14:26:44.639037Z","iopub.status.idle":"2024-11-24T14:27:00.010448Z","shell.execute_reply.started":"2024-11-24T14:26:44.638991Z","shell.execute_reply":"2024-11-24T14:27:00.009243Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Import Libraries","metadata":{"papermill":{"duration":0.007921,"end_time":"2024-11-22T07:58:56.471192","exception":false,"start_time":"2024-11-22T07:58:56.463271","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\nimport os\n\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision \nfrom torchvision import transforms\n# from torchinfo import summary\nimport timm\nimport segmentation_models_pytorch as smp\nimport wandb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":9.073439,"end_time":"2024-11-22T07:59:05.552469","exception":false,"start_time":"2024-11-22T07:58:56.479030","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:00.012697Z","iopub.execute_input":"2024-11-24T14:27:00.013076Z","iopub.status.idle":"2024-11-24T14:27:08.754432Z","shell.execute_reply.started":"2024-11-24T14:27:00.013032Z","shell.execute_reply":"2024-11-24T14:27:08.753492Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"papermill":{"duration":1.042737,"end_time":"2024-11-22T07:59:06.603417","exception":false,"start_time":"2024-11-22T07:59:05.560680","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:08.755582Z","iopub.execute_input":"2024-11-24T14:27:08.755860Z","iopub.status.idle":"2024-11-24T14:27:09.803453Z","shell.execute_reply.started":"2024-11-24T14:27:08.755833Z","shell.execute_reply":"2024-11-24T14:27:09.802608Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"papermill":{"duration":0.070705,"end_time":"2024-11-22T07:59:06.682562","exception":false,"start_time":"2024-11-22T07:59:06.611857","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:09.805492Z","iopub.execute_input":"2024-11-24T14:27:09.805801Z","iopub.status.idle":"2024-11-24T14:27:09.860047Z","shell.execute_reply.started":"2024-11-24T14:27:09.805772Z","shell.execute_reply":"2024-11-24T14:27:09.859055Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Read data","metadata":{"papermill":{"duration":0.008027,"end_time":"2024-11-22T07:59:06.698842","exception":false,"start_time":"2024-11-22T07:59:06.690815","status":"completed"},"tags":[]}},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nimage_path = []\nTRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nfor root, dirs, files in os.walk(TRAIN_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        image_path.append(path)\n        \nlen(image_path)","metadata":{"papermill":{"duration":2.062344,"end_time":"2024-11-22T07:59:08.768987","exception":false,"start_time":"2024-11-22T07:59:06.706643","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:09.861173Z","iopub.execute_input":"2024-11-24T14:27:09.861492Z","iopub.status.idle":"2024-11-24T14:27:10.362238Z","shell.execute_reply.started":"2024-11-24T14:27:09.861464Z","shell.execute_reply":"2024-11-24T14:27:10.361408Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"mask_path = []\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\nfor root, dirs, files in os.walk(TRAIN_MASK_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_path.append(path)\n        \nlen(mask_path)","metadata":{"papermill":{"duration":2.148976,"end_time":"2024-11-22T07:59:10.971398","exception":false,"start_time":"2024-11-22T07:59:08.822422","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.363397Z","iopub.execute_input":"2024-11-24T14:27:10.363776Z","iopub.status.idle":"2024-11-24T14:27:10.750687Z","shell.execute_reply.started":"2024-11-24T14:27:10.363737Z","shell.execute_reply":"2024-11-24T14:27:10.749850Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.resize = resize\n        self.transform = transform\n        self.images = os.listdir(self.img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n        lower_red1 = np.array([0, 100, 20])\n        upper_red1 = np.array([10, 255, 255])\n        lower_red2 = np.array([160,100,20])\n        upper_red2 = np.array([179,255,255])\n        \n        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n        \n        red_mask = lower_mask_red + upper_mask_red\n        red_mask[red_mask != 0] = 1\n\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        \n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        label_path = os.path.join(self.label_dir, self.images[idx])\n        image = cv2.imread(img_path)  #  BGR\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label\n    \nclass TestDataset(Dataset):\n    def __init__(self, img_dir=\"path/to/data\", resize = None, transform=None):\n        self.img_dir = img_dir\n        self.transform = transform\n        self.resize = resize\n        self.images = os.listdir(self.img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        image = cv2.imread(img_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        height, width, channels = image.shape\n        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n        name =  os.path.basename(img_path)\n        if self.transform:\n            transformed = self.transform(image=image)\n            image = transformed[\"image\"]\n        return image, height, width, name[:-5]","metadata":{"papermill":{"duration":0.020151,"end_time":"2024-11-22T07:59:11.000333","exception":false,"start_time":"2024-11-22T07:59:10.980182","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.751752Z","iopub.execute_input":"2024-11-24T14:27:10.751986Z","iopub.status.idle":"2024-11-24T14:27:10.763681Z","shell.execute_reply.started":"2024-11-24T14:27:10.751963Z","shell.execute_reply":"2024-11-24T14:27:10.762879Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Hyperparameters","metadata":{}},{"cell_type":"code","source":"img_resize = (256, 256)\nbatch_size = 32\nlearning_rate = 1e-3\nalpha = 0.5  # Weight of cross entropy loss ","metadata":{"papermill":{"duration":0.014571,"end_time":"2024-11-22T07:59:11.023189","exception":false,"start_time":"2024-11-22T07:59:11.008618","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.764748Z","iopub.execute_input":"2024-11-24T14:27:10.765056Z","iopub.status.idle":"2024-11-24T14:27:10.781478Z","shell.execute_reply.started":"2024-11-24T14:27:10.765020Z","shell.execute_reply":"2024-11-24T14:27:10.780643Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dataset = TrainDataset(img_dir= TRAIN_DIR,\n                             label_dir= TRAIN_MASK_DIR,\n                             resize= img_resize,\n                             transform = None)","metadata":{"papermill":{"duration":0.015186,"end_time":"2024-11-22T07:59:11.046408","exception":false,"start_time":"2024-11-22T07:59:11.031222","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.782786Z","iopub.execute_input":"2024-11-24T14:27:10.783127Z","iopub.status.idle":"2024-11-24T14:27:10.798508Z","shell.execute_reply.started":"2024-11-24T14:27:10.783088Z","shell.execute_reply":"2024-11-24T14:27:10.797775Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Augmentation","metadata":{"papermill":{"duration":0.00789,"end_time":"2024-11-22T07:59:11.062462","exception":false,"start_time":"2024-11-22T07:59:11.054572","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class AugmentDataset(Dataset):\n    def __init__(self, dataset, transform=None, length_multiplier=1):\n        self.dataset = dataset\n        self.transform = transform\n        self.length_multiplier = length_multiplier\n        \n    def __getitem__(self, idx):\n        actual_idx = idx % len(self.dataset)\n        image, label = self.dataset[actual_idx]\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image'].float()\n            label = transformed['mask'].float()\n            label = label.permute(2, 0, 1)\n        return image, label\n\n    def __len__(self):\n        return len(self.dataset) * self.length_multiplier","metadata":{"papermill":{"duration":0.015701,"end_time":"2024-11-22T07:59:11.086242","exception":false,"start_time":"2024-11-22T07:59:11.070541","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.801049Z","iopub.execute_input":"2024-11-24T14:27:10.801402Z","iopub.status.idle":"2024-11-24T14:27:10.812736Z","shell.execute_reply.started":"2024-11-24T14:27:10.801371Z","shell.execute_reply":"2024-11-24T14:27:10.811935Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transformation = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\nval_transformation = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n# train_transformation = A.Compose([\n#     A.HorizontalFlip(p=0.5),\n#     A.VerticalFlip(p=0.5),\n#     A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n#     A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n#     A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()], p=0.35),\n#     A.CoarseDropout(p=0.2, max_height=15, max_width=15, fill_value=255),\n#     A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n# #     A.RandomShadow(p=0.1),\n#     A.ShiftScaleRotate(p=0.15, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n#     A.RandomCrop((img_resize, img_resize)),\n#     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n#     ToTensorV2(),\n# ])\nclass UnNormalize(object):\n    def __init__(self, mean, std):\n        self.mean = mean\n        self.std = std\n        \n    def __call__(self, tensor):\n        \"\"\"\n        Args:\n            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n        Returns:\n            Tensor: Normalized image.\n        \"\"\"\n        for t, m, s in zip(tensor, self.mean, self.std):\n            t.mul_(s).add_(m)\n            # The normalize code -> t.sub_(m).div_(s)\n        return tensor\n    \nunorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))","metadata":{"papermill":{"duration":0.016188,"end_time":"2024-11-22T07:59:11.110686","exception":false,"start_time":"2024-11-22T07:59:11.094498","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.813780Z","iopub.execute_input":"2024-11-24T14:27:10.814115Z","iopub.status.idle":"2024-11-24T14:27:10.826881Z","shell.execute_reply.started":"2024-11-24T14:27:10.814079Z","shell.execute_reply":"2024-11-24T14:27:10.826121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Define the split sizes\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Randomly split the dataset\ngenerator = torch.Generator().manual_seed(7)\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n\ntrain_dataset = AugmentDataset(train_dataset, transform=train_transformation, length_multiplier=2)\nval_dataset = AugmentDataset(val_dataset, transform=val_transformation)\n# test_dataset = AugmentDataset(test_dataset, transform=val_transformation)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"papermill":{"duration":0.02281,"end_time":"2024-11-22T07:59:11.141595","exception":false,"start_time":"2024-11-22T07:59:11.118785","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:37:19.611145Z","iopub.execute_input":"2024-11-24T14:37:19.611504Z","iopub.status.idle":"2024-11-24T14:37:19.617600Z","shell.execute_reply.started":"2024-11-24T14:37:19.611469Z","shell.execute_reply":"2024-11-24T14:37:19.616917Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_dataset = TestDataset(img_dir=\"/kaggle/input/bkai-igh-neopolyp/test/test\", resize=img_resize, transform=val_transformation)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.854889Z","iopub.execute_input":"2024-11-24T14:27:10.855121Z","iopub.status.idle":"2024-11-24T14:27:10.892052Z","shell.execute_reply.started":"2024-11-24T14:27:10.855097Z","shell.execute_reply":"2024-11-24T14:27:10.891460Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.893012Z","iopub.execute_input":"2024-11-24T14:27:10.893343Z","iopub.status.idle":"2024-11-24T14:27:10.897467Z","shell.execute_reply.started":"2024-11-24T14:27:10.893306Z","shell.execute_reply":"2024-11-24T14:27:10.896644Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(train_dataset), len(val_dataset), len(test_dataset)","metadata":{"papermill":{"duration":0.015445,"end_time":"2024-11-22T07:59:11.165016","exception":false,"start_time":"2024-11-22T07:59:11.149571","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.898603Z","iopub.execute_input":"2024-11-24T14:27:10.899171Z","iopub.status.idle":"2024-11-24T14:27:10.908623Z","shell.execute_reply.started":"2024-11-24T14:27:10.899128Z","shell.execute_reply":"2024-11-24T14:27:10.907962Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def show_images(images, labels=None, title=\"\"):\n    fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n    if len(images) == 1:\n        axes = [axes]\n    for i, img in enumerate(images):\n        img = unorm(img)\n        img = img.permute(1, 2, 0).cpu().numpy()\n        axes[i].imshow(img)\n        if labels is not None:\n            axes[i].imshow(labels[i].squeeze().cpu().numpy(), alpha=0.5, cmap='jet')\n        axes[i].axis('off')\n    fig.suptitle(title)\n    plt.show()\n    \n# def visualize_samples(train_loader, val_loader, test_loader, unorm, num_samples=3):\n#     # Visualize train samples\n#     train_images, train_labels = next(iter(train_loader))\n#     show_images(train_images[:num_samples], train_labels[:num_samples], title=\"Train Samples\")\n\n#     # Visualize validation samples\n#     val_images, val_labels = next(iter(val_loader))\n#     show_images(val_images[:num_samples], val_labels[:num_samples], title=\"Validation Samples\")\n\n#     # Visualize test samples\n#     test_images, _, _, _ = next(iter(test_loader))\n#     show_images(test_images[:num_samples], title=\"Test Samples\")\n\n# visualize_samples(train_loader, val_loader, test_loader, unorm)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:02:04.231952Z","iopub.execute_input":"2024-11-24T15:02:04.232696Z","iopub.status.idle":"2024-11-24T15:02:04.239032Z","shell.execute_reply.started":"2024-11-24T15:02:04.232660Z","shell.execute_reply":"2024-11-24T15:02:04.237970Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Define Model","metadata":{"papermill":{"duration":0.008004,"end_time":"2024-11-22T07:59:11.181239","exception":false,"start_time":"2024-11-22T07:59:11.173235","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class DoubleConv(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DoubleConv, self).__init__()\n        self.double_conv = nn.Sequential(\n            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(inplace=True),\n            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n            nn.BatchNorm2d(out_channels),\n            nn.LeakyReLU(inplace=True),\n        )\n\n    def forward(self, x):\n        return self.double_conv(x)\n    \n    \nclass DownBlock(nn.Module):\n    def __init__(self, in_channels, out_channels):\n        super(DownBlock, self).__init__()\n        self.double_conv = DoubleConv(in_channels, out_channels)\n        self.down_sample = nn.MaxPool2d(2)\n\n    def forward(self, x):\n        skip_out = self.double_conv(x)\n        down_out = self.down_sample(skip_out)\n        return (down_out, skip_out)\n\n    \nclass UpBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, up_sample_mode):\n        super(UpBlock, self).__init__()\n        if up_sample_mode == 'conv_transpose':\n            if out_channels*4 == in_channels:\n                self.up_sample = nn.ConvTranspose2d(in_channels-out_channels*2, in_channels-out_channels*2, kernel_size=2, stride=2) \n            else:\n                self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n        else:\n            self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.double_conv = DoubleConv(in_channels, out_channels)\n\n    def forward(self, down_input, skip_input):\n#         print(\"down\", down_input.shape)\n#         print(\"skip\", skip_input.shape)\n        x = self.up_sample(down_input)\n#         print(\"x\",x.shape)\n        x = torch.cat([x, skip_input], dim=1)\n        return self.double_conv(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.920749Z","iopub.execute_input":"2024-11-24T14:27:10.921044Z","iopub.status.idle":"2024-11-24T14:27:10.934928Z","shell.execute_reply.started":"2024-11-24T14:27:10.921017Z","shell.execute_reply":"2024-11-24T14:27:10.934059Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ResUnet\nclass PolypModel(nn.Module):\n    def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n        super().__init__()\n        self.out_classes = out_classes\n        self.backbone = timm.create_model(\"resnet152\", pretrained=True, features_only=True)\n#         self.down_conv1 = DownBlock(3, 64)\n        self.down_conv1 = DownBlock(64, 128)\n        self.down_conv2 = DownBlock(256, 512)\n        self.down_conv3 = DownBlock(512, 1024)\n        self.down_conv4 = DownBlock(1024, 2048)\n        self.up_sample_mode = up_sample_mode\n        self.block_neck = DoubleConv(2048, 1024)\n        self.block_up1 = UpBlock(1024+1024, 512,self.up_sample_mode)\n        self.block_up2 = UpBlock(512+512, 256,self.up_sample_mode)\n        self.block_up3 = UpBlock(256+256, 128,self.up_sample_mode)\n        self.block_up4 = UpBlock(128+64, 64,self.up_sample_mode)\n        self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n        self.final_activation = nn.Softmax(dim=1)\n\n    def forward(self, x):\n        x1, x2, x3, x4, x5 = self.backbone(x)\n        x = self.block_neck(x5) # x (B, 1024, 8, 8)\n        x = self.block_up1(x, x4)\n        x = self.block_up2(x, x3)\n        x = self.block_up3(x, x2)\n        x = self.block_up4(x, x1 )\n        x = self.conv_last(x)\n        x = self.upsample(x)\n        x = self.final_activation(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.935884Z","iopub.execute_input":"2024-11-24T14:27:10.936119Z","iopub.status.idle":"2024-11-24T14:27:10.951229Z","shell.execute_reply.started":"2024-11-24T14:27:10.936095Z","shell.execute_reply":"2024-11-24T14:27:10.950359Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = PolypModel()\n\nimport segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet152\",        \n    # encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)","metadata":{"papermill":{"duration":0.918369,"end_time":"2024-11-22T07:59:12.107789","exception":false,"start_time":"2024-11-22T07:59:11.189420","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:10.952325Z","iopub.execute_input":"2024-11-24T14:27:10.952622Z","iopub.status.idle":"2024-11-24T14:27:14.651316Z","shell.execute_reply.started":"2024-11-24T14:27:10.952559Z","shell.execute_reply":"2024-11-24T14:27:14.650639Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# checkpoint = torch.load('/kaggle/input/kaggle-notebook/model.pth')\n# model.load_state_dict(checkpoint['model'])\n# model.to(device)","metadata":{"papermill":{"duration":0.014743,"end_time":"2024-11-22T07:59:12.131562","exception":false,"start_time":"2024-11-22T07:59:12.116819","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:14.652354Z","iopub.execute_input":"2024-11-24T14:27:14.652680Z","iopub.status.idle":"2024-11-24T14:27:14.656515Z","shell.execute_reply.started":"2024-11-24T14:27:14.652644Z","shell.execute_reply":"2024-11-24T14:27:14.655499Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"color_dict= {0: (0, 0, 0),\n             1: (255, 0, 0),\n             2: (0, 255, 0)}\ndef mask_to_rgb(mask, color_dict):\n    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n\n    for k in color_dict.keys():\n        output[mask==k] = color_dict[k]\n\n    return np.uint8(output)    ","metadata":{"papermill":{"duration":0.015115,"end_time":"2024-11-22T07:59:12.155363","exception":false,"start_time":"2024-11-22T07:59:12.140248","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:14.657662Z","iopub.execute_input":"2024-11-24T14:27:14.657993Z","iopub.status.idle":"2024-11-24T14:27:14.669626Z","shell.execute_reply.started":"2024-11-24T14:27:14.657951Z","shell.execute_reply":"2024-11-24T14:27:14.668921Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# del train_dataset\n# del val_dataset\n# del test_dataset","metadata":{"papermill":{"duration":0.013967,"end_time":"2024-11-22T07:59:12.177957","exception":false,"start_time":"2024-11-22T07:59:12.163990","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:14.670705Z","iopub.execute_input":"2024-11-24T14:27:14.671539Z","iopub.status.idle":"2024-11-24T14:27:14.684191Z","shell.execute_reply.started":"2024-11-24T14:27:14.671512Z","shell.execute_reply":"2024-11-24T14:27:14.683598Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Train","metadata":{"papermill":{"duration":0.008446,"end_time":"2024-11-22T07:59:12.194862","exception":false,"start_time":"2024-11-22T07:59:12.186416","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"Define Dice loss function","metadata":{"papermill":{"duration":0.008242,"end_time":"2024-11-22T07:59:12.211599","exception":false,"start_time":"2024-11-22T07:59:12.203357","status":"completed"},"tags":[]}},{"cell_type":"code","source":"criterion_ce = nn.CrossEntropyLoss()\ncriterion_dice = smp.losses.DiceLoss(mode='multiclass')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:14.685255Z","iopub.execute_input":"2024-11-24T14:27:14.685573Z","iopub.status.idle":"2024-11-24T14:27:14.695799Z","shell.execute_reply.started":"2024-11-24T14:27:14.685537Z","shell.execute_reply":"2024-11-24T14:27:14.694989Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# model = smp.UnetPlusPlus(\n#     encoder_name=\"resnet34\",        \n#     # encoder_weights=\"imagenet\",     \n#     in_channels=3,                  \n#     classes=3     \n# )\n# model = PolypModel()\n# checkpoint = torch.load('/kaggle/input/model-polyp/colorization_model.pth')\n# model.load_state_dict(checkpoint['model_state_dict'])\n# model = model.to(device)\ncheckpoint = torch.load('/kaggle/input/unetplusplus-resnet152/model.pth')\nmodel.load_state_dict(checkpoint['model'])\nmodel = model.to(device)","metadata":{"papermill":{"duration":0.293697,"end_time":"2024-11-22T09:12:39.073343","exception":false,"start_time":"2024-11-22T09:12:38.779646","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:14.696845Z","iopub.execute_input":"2024-11-24T14:27:14.697125Z","iopub.status.idle":"2024-11-24T14:27:22.013228Z","shell.execute_reply.started":"2024-11-24T14:27:14.697090Z","shell.execute_reply":"2024-11-24T14:27:22.012524Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nmodel.eval()\nval_loss = 0\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        labels = labels.squeeze(dim=1).long()\n        \n        outputs = model(images)\n        loss_dice = criterion_dice(outputs, labels)\n        print(loss_dice.item())\n        val_loss += loss_dice.item() * images.size(0)\n        \n        # Show images, outputs, and labels\n        _, preds = torch.max(outputs, 1)\n        images = images.cpu()\n        labels = labels.cpu()\n        preds = preds.cpu()\n        for i in range(images.size(0)):\n            plt.figure(figsize=(15, 5))\n            plt.subplot(1, 3, 1)\n            plt.imshow(images[i].permute(1, 2, 0))\n            plt.title(\"Input Image\")\n            plt.axis('off')\n\n            plt.subplot(1, 3, 2)\n            plt.imshow(labels[i], cmap='gray')\n            plt.title(\"Ground Truth\")\n            plt.axis('off')\n\n            plt.subplot(1, 3, 3)\n            plt.imshow(preds[i], cmap='gray')\n            plt.title(\"Predicted Output\")\n            plt.axis('off')\n\n            plt.show()\n                \nprint(f\"Loss: {val_loss/len(val_loader.dataset):.10f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T15:02:51.252745Z","iopub.execute_input":"2024-11-24T15:02:51.253103Z","iopub.status.idle":"2024-11-24T15:04:06.103648Z","shell.execute_reply.started":"2024-11-24T15:02:51.253071Z","shell.execute_reply":"2024-11-24T15:04:06.102945Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nval_loss = 0\nwith torch.no_grad():\n    for images, labels in val_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n        labels = labels.squeeze(dim=1).long()\n        \n        outputs = model(images)\n        # loss_ce = criterion_ce(outputs, labels)\n        loss_dice = criterion_dice(outputs, labels)\n        # loss = alpha * loss_ce + (1 - alpha) * loss_dice\n        print(loss_dice.item())\n        val_loss += loss_dice.item() * images.size(0)\nprint(f\"Loss: {val_loss/len(val_loader.dataset):.10f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:37:25.121055Z","iopub.execute_input":"2024-11-24T14:37:25.121850Z","iopub.status.idle":"2024-11-24T14:37:35.254369Z","shell.execute_reply.started":"2024-11-24T14:37:25.121815Z","shell.execute_reply":"2024-11-24T14:37:35.253493Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!mkdir prediction","metadata":{"papermill":{"duration":1.04678,"end_time":"2024-11-22T09:12:40.186542","exception":false,"start_time":"2024-11-22T09:12:39.139762","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:25.437559Z","iopub.status.idle":"2024-11-24T14:27:25.437903Z","shell.execute_reply.started":"2024-11-24T14:27:25.437749Z","shell.execute_reply":"2024-11-24T14:27:25.437765Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Get Testset Prediction","metadata":{"papermill":{"duration":0.013495,"end_time":"2024-11-22T09:12:40.214453","exception":false,"start_time":"2024-11-22T09:12:40.200958","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import cv2\nimport numpy as np\n\ndef Smoothed_img(image):\n    resized_image = image\n    smoothed_image = cv2.GaussianBlur(resized_image, (15, 15), 0)\n    red_pixels = (smoothed_image[:, :, 2] > 100)\n    green_pixels = (smoothed_image[:, :, 1] > 100)\n    black_pixels = ~(red_pixels | green_pixels)\n    smoothed_image[red_pixels] = [0, 0, 255]\n    smoothed_image[green_pixels] = [0, 255, 0]\n    smoothed_image[black_pixels] = [0, 0, 0]\n\n    # pixel_values = np.array(smoothed_image)\n    # unique_values = np.unique(pixel_values)\n    # print(unique_values)\n    return smoothed_image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:25.439119Z","iopub.status.idle":"2024-11-24T14:27:25.439470Z","shell.execute_reply.started":"2024-11-24T14:27:25.439319Z","shell.execute_reply":"2024-11-24T14:27:25.439336Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    for image, h, w, name in test_loader:\n        outputs = model(image.to(device))\n        outputs = outputs.squeeze().cpu().numpy()\n        outputs = np.argmax(outputs, axis=0)\n        outputs = mask_to_rgb(outputs, color_dict)\n        w = w.item()\n        h = h.item()\n        new_size = (w, h)\n        resized_image = cv2.resize(outputs, new_size, interpolation=cv2.INTER_CUBIC)\n        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n        resized_image = Smoothed_img(resized_image)\n        cv2.imwrite(f\"prediction/{name[0]}.png\", resized_image)\n        ","metadata":{"papermill":{"duration":28.547731,"end_time":"2024-11-22T09:13:08.775910","exception":false,"start_time":"2024-11-22T09:12:40.228179","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:25.440726Z","iopub.status.idle":"2024-11-24T14:27:25.441137Z","shell.execute_reply.started":"2024-11-24T14:27:25.440918Z","shell.execute_reply":"2024-11-24T14:27:25.440941Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    \n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        # print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/prediction'\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"papermill":{"duration":2.808302,"end_time":"2024-11-22T09:13:11.609364","exception":false,"start_time":"2024-11-22T09:13:08.801062","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-11-24T14:27:25.442568Z","iopub.status.idle":"2024-11-24T14:27:25.443010Z","shell.execute_reply.started":"2024-11-24T14:27:25.442791Z","shell.execute_reply":"2024-11-24T14:27:25.442814Z"}},"outputs":[],"execution_count":null}]}