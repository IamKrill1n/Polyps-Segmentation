{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"databundleVersionId":2715462,"sourceId":30892,"sourceType":"competition"}],"dockerImageVersionId":30580,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":825.264438,"end_time":"2024-11-18T15:04:57.330171","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-11-18T14:51:12.065733","version":"2.4.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Install Libraries","metadata":{}},{"cell_type":"code","source":"!pip install torchsummary\n!pip install torchgeometry\n!pip install segmentation-models-pytorch","metadata":{"papermill":{"duration":25.226006,"end_time":"2024-11-18T14:51:40.725159","exception":false,"start_time":"2024-11-18T14:51:15.499153","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:36:36.767021Z","iopub.execute_input":"2024-11-20T18:36:36.767252Z","iopub.status.idle":"2024-11-20T18:37:01.859543Z","shell.execute_reply.started":"2024-11-20T18:36:36.767229Z","shell.execute_reply":"2024-11-20T18:37:01.857529Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /opt/conda/lib/python3.10/site-packages (1.5.1)\nRequirement already satisfied: torchgeometry in /opt/conda/lib/python3.10/site-packages (0.1.2)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\nRequirement already satisfied: segmentation-models-pytorch in /opt/conda/lib/python3.10/site-packages (0.3.4)\nRequirement already satisfied: efficientnet-pytorch==0.7.1 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.1)\nRequirement already satisfied: huggingface-hub>=0.24.6 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.26.2)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\nRequirement already satisfied: pretrainedmodels==0.7.4 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.7.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\nRequirement already satisfied: timm==0.9.7 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.9.7)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\nRequirement already satisfied: munch in /opt/conda/lib/python3.10/site-packages (from pretrainedmodels==0.7.4->segmentation-models-pytorch) (4.0.0)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.1)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.12.2)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.31.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.5.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.7.22)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nfrom torchvision.io import read_image\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, random_split, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nfrom torchvision.transforms import ToTensor\nfrom PIL import Image\nimport os\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision \nfrom torchvision import transforms\nfrom torchinfo import summary\nimport timm\nimport segmentation_models_pytorch as smp\nimport wandb","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.884747,"end_time":"2024-11-18T14:52:08.771554","exception":false,"start_time":"2024-11-18T14:51:59.886807","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:01.860805Z","iopub.execute_input":"2024-11-20T18:37:01.861077Z","iopub.status.idle":"2024-11-20T18:37:06.274125Z","shell.execute_reply.started":"2024-11-20T18:37:01.861053Z","shell.execute_reply":"2024-11-20T18:37:06.273455Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"code","source":"!nvidia-smi -L","metadata":{"papermill":{"duration":1.071255,"end_time":"2024-11-18T14:52:09.854408","exception":false,"start_time":"2024-11-18T14:52:08.783153","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:06.275037Z","iopub.execute_input":"2024-11-20T18:37:06.275275Z","iopub.status.idle":"2024-11-20T18:37:07.326600Z","shell.execute_reply.started":"2024-11-20T18:37:06.275238Z","shell.execute_reply":"2024-11-20T18:37:07.325565Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-025592e3-86c8-d06f-3f41-0b97fec51bd9)\n","output_type":"stream"}]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"papermill":{"duration":0.087726,"end_time":"2024-11-18T14:52:09.953545","exception":false,"start_time":"2024-11-18T14:52:09.865819","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.329317Z","iopub.execute_input":"2024-11-20T18:37:07.329620Z","iopub.status.idle":"2024-11-20T18:37:07.372297Z","shell.execute_reply.started":"2024-11-20T18:37:07.329595Z","shell.execute_reply":"2024-11-20T18:37:07.371452Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"markdown","source":"## Read data","metadata":{}},{"cell_type":"code","source":"images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\nimage_path = []\nTRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\nfor root, dirs, files in os.walk(TRAIN_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        image_path.append(path)\n        \nlen(image_path)","metadata":{"papermill":{"duration":0.603545,"end_time":"2024-11-18T14:52:10.607500","exception":false,"start_time":"2024-11-18T14:52:10.003955","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.373587Z","iopub.execute_input":"2024-11-20T18:37:07.373857Z","iopub.status.idle":"2024-11-20T18:37:07.598754Z","shell.execute_reply.started":"2024-11-20T18:37:07.373834Z","shell.execute_reply":"2024-11-20T18:37:07.597716Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"mask_path = []\nTRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\nfor root, dirs, files in os.walk(TRAIN_MASK_DIR):\n    for file in files:\n        path = os.path.join(root,file)\n        mask_path.append(path)\n        \nlen(mask_path)","metadata":{"papermill":{"duration":0.502775,"end_time":"2024-11-18T14:52:11.122049","exception":false,"start_time":"2024-11-18T14:52:10.619274","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.600078Z","iopub.execute_input":"2024-11-20T18:37:07.600467Z","iopub.status.idle":"2024-11-20T18:37:07.779072Z","shell.execute_reply.started":"2024-11-20T18:37:07.600440Z","shell.execute_reply":"2024-11-20T18:37:07.778184Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"1000"},"metadata":{}}]},{"cell_type":"code","source":"class DatasetCustom(Dataset):\n    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n        self.img_dir = img_dir\n        self.label_dir = label_dir\n        self.resize = resize\n        self.transform = transform\n        self.images = os.listdir(self.img_dir)\n\n    def __len__(self):\n        return len(self.images)\n    \n    def read_mask(self, mask_path):\n        image = cv2.imread(mask_path)\n        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n\n        lower_red1 = np.array([0, 100, 20])\n        upper_red1 = np.array([10, 255, 255])\n        lower_red2 = np.array([160,100,20])\n        upper_red2 = np.array([179,255,255])\n        \n        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n        \n        red_mask = lower_mask_red + upper_mask_red\n        red_mask[red_mask != 0] = 1\n\n        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n        green_mask[green_mask != 0] = 2\n\n        full_mask = cv2.bitwise_or(red_mask, green_mask)\n        full_mask = np.expand_dims(full_mask, axis=-1) \n        full_mask = full_mask.astype(np.uint8)\n        \n        return full_mask\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.images[idx])\n        label_path = os.path.join(self.label_dir, self.images[idx])\n        image = cv2.imread(img_path)  #  BGR\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n        label = self.read_mask(label_path)  \n        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n        if self.transform:\n            image = self.transform(image)\n            \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:37:07.780204Z","iopub.execute_input":"2024-11-20T18:37:07.780481Z","iopub.status.idle":"2024-11-20T18:37:07.789604Z","shell.execute_reply.started":"2024-11-20T18:37:07.780459Z","shell.execute_reply":"2024-11-20T18:37:07.788672Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"img_resize = (320, 320)","metadata":{"papermill":{"duration":0.020361,"end_time":"2024-11-18T14:52:11.154855","exception":false,"start_time":"2024-11-18T14:52:11.134494","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.790676Z","iopub.execute_input":"2024-11-20T18:37:07.790916Z","iopub.status.idle":"2024-11-20T18:37:07.802967Z","shell.execute_reply.started":"2024-11-20T18:37:07.790894Z","shell.execute_reply":"2024-11-20T18:37:07.802293Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset = DatasetCustom(img_dir= TRAIN_DIR,\n                             label_dir= TRAIN_MASK_DIR,\n                             resize= img_resize,\n                             transform = None)","metadata":{"papermill":{"duration":0.020361,"end_time":"2024-11-18T14:52:11.154855","exception":false,"start_time":"2024-11-18T14:52:11.134494","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.804114Z","iopub.execute_input":"2024-11-20T18:37:07.804380Z","iopub.status.idle":"2024-11-20T18:37:07.814705Z","shell.execute_reply.started":"2024-11-20T18:37:07.804355Z","shell.execute_reply":"2024-11-20T18:37:07.814004Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"## Augmentation","metadata":{}},{"cell_type":"code","source":"class AugmentDataset(Dataset):\n    def __init__(self, dataset, transform=None, length_multiplier=1):\n        self.dataset = dataset\n        self.transform = transform\n        self.length_multiplier = length_multiplier\n        \n    def __getitem__(self, idx):\n        actual_idx = idx % len(self.dataset)\n        image, label = self.dataset[actual_idx]\n        if self.transform:\n            transformed = self.transform(image=image, mask=label)\n            image = transformed['image'].float()\n            label = transformed['mask'].float()\n            label = label.permute(2, 0, 1)\n        return image, label\n\n    def __len__(self):\n        return len(self.dataset) * self.length_multiplier","metadata":{"papermill":{"duration":0.022169,"end_time":"2024-11-18T14:52:56.115302","exception":false,"start_time":"2024-11-18T14:52:56.093133","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.815601Z","iopub.execute_input":"2024-11-20T18:37:07.815808Z","iopub.status.idle":"2024-11-20T18:37:07.827089Z","shell.execute_reply.started":"2024-11-20T18:37:07.815787Z","shell.execute_reply":"2024-11-20T18:37:07.826431Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"train_transformation = A.Compose([\n    A.HorizontalFlip(p=0.5),\n    A.VerticalFlip(p=0.5),\n    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])\n\nval_transformation = A.Compose([\n    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n    ToTensorV2(),\n])","metadata":{"papermill":{"duration":0.022255,"end_time":"2024-11-18T14:52:56.149898","exception":false,"start_time":"2024-11-18T14:52:56.127643","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.828092Z","iopub.execute_input":"2024-11-20T18:37:07.828444Z","iopub.status.idle":"2024-11-20T18:37:07.846409Z","shell.execute_reply.started":"2024-11-20T18:37:07.828412Z","shell.execute_reply":"2024-11-20T18:37:07.845619Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Define the split sizes\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\n\n# Define the batch size\nbatch_size = 32\n# Randomly split the dataset\ngenerator = torch.Generator().manual_seed(42)\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n\ntrain_dataset = AugmentDataset(train_dataset, transform=train_transformation, length_multiplier=2)\nval_dataset = AugmentDataset(val_dataset, transform=val_transformation)\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)","metadata":{"papermill":{"duration":0.020831,"end_time":"2024-11-18T14:52:56.182852","exception":false,"start_time":"2024-11-18T14:52:56.162021","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:07.847339Z","iopub.execute_input":"2024-11-20T18:37:07.847584Z","iopub.status.idle":"2024-11-20T18:37:07.857096Z","shell.execute_reply.started":"2024-11-20T18:37:07.847562Z","shell.execute_reply":"2024-11-20T18:37:07.856312Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Define Model","metadata":{}},{"cell_type":"code","source":"import segmentation_models_pytorch as smp\n\nmodel = smp.UnetPlusPlus(\n    encoder_name=\"resnet34\",        \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:37:07.860113Z","iopub.execute_input":"2024-11-20T18:37:07.860375Z","iopub.status.idle":"2024-11-20T18:37:08.504551Z","shell.execute_reply.started":"2024-11-20T18:37:07.860353Z","shell.execute_reply":"2024-11-20T18:37:08.503842Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"color_dict= {0: (0, 0, 0),\n             1: (255, 0, 0),\n             2: (0, 255, 0)}\ndef mask_to_rgb(mask, color_dict):\n    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n\n    for k in color_dict.keys():\n        output[mask==k] = color_dict[k]\n\n    return np.uint8(output)    ","metadata":{"papermill":{"duration":0.020036,"end_time":"2024-11-18T14:52:56.246685","exception":false,"start_time":"2024-11-18T14:52:56.226649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:08.505522Z","iopub.execute_input":"2024-11-20T18:37:08.505760Z","iopub.status.idle":"2024-11-20T18:37:08.510984Z","shell.execute_reply.started":"2024-11-20T18:37:08.505739Z","shell.execute_reply":"2024-11-20T18:37:08.510178Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"del dataset\ndel train_dataset\ndel val_dataset","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:37:08.512139Z","iopub.execute_input":"2024-11-20T18:37:08.512494Z","iopub.status.idle":"2024-11-20T18:37:08.528864Z","shell.execute_reply.started":"2024-11-20T18:37:08.512461Z","shell.execute_reply":"2024-11-20T18:37:08.528008Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"markdown","source":"Define Dice loss function","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n\nclass DiceLoss(nn.Module):\n    def __init__(self, num_classes=3, epsilon=1e-6):\n        super(DiceLoss, self).__init__()\n        self.num_classes = num_classes\n        self.epsilon = epsilon\n\n    def forward(self, outputs, targets):\n        outputs = F.softmax(outputs, dim=1)\n        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n\n        # Flatten the tensors\n        outputs_flat = outputs.contiguous().view(-1, self.num_classes)\n        targets_flat = targets_one_hot.contiguous().view(-1, self.num_classes)\n\n        intersection = torch.sum(outputs_flat * targets_flat, dim=0)\n        union = torch.sum(outputs_flat + targets_flat, dim=0)\n\n        dice_loss = 1 - (2 * intersection + self.epsilon) / (union + self.epsilon)\n        mean_dice_loss = dice_loss.mean()\n\n        return mean_dice_loss","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:37:08.529871Z","iopub.execute_input":"2024-11-20T18:37:08.530223Z","iopub.status.idle":"2024-11-20T18:37:08.539929Z","shell.execute_reply.started":"2024-11-20T18:37:08.530197Z","shell.execute_reply":"2024-11-20T18:37:08.539209Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nmodel.to(device)\ncriterion_ce = nn.CrossEntropyLoss()\ncriterion_dice = DiceLoss(num_classes=3)\nalpha = 0.5  # Weight for balancing the two losses\nbest_val_loss = 999","metadata":{"papermill":{"duration":645.298148,"end_time":"2024-11-18T15:04:25.412141","exception":false,"start_time":"2024-11-18T14:53:40.113993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:08.540757Z","iopub.execute_input":"2024-11-20T18:37:08.540980Z","iopub.status.idle":"2024-11-20T18:37:08.695810Z","shell.execute_reply.started":"2024-11-20T18:37:08.540960Z","shell.execute_reply":"2024-11-20T18:37:08.695110Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"Make use of learning rate scheduler","metadata":{}},{"cell_type":"code","source":"import torch.optim as optim\n\n# Assuming you've already defined your optimizer\nlearning_rate = 0.0001\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Initialize the scheduler\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(\n    optimizer, \n    mode='min',                 # We want to minimize the validation loss\n    factor=0.5,                 # Reduce LR by a factor of 0.5\n    patience=2,                 # Number of epochs with no improvement after which LR will be reduced\n    verbose=True,               # Print a message when LR is updated\n    threshold=0.0001,           # Threshold for measuring the new optimum\n    threshold_mode='rel',       # Mode for threshold\n    cooldown=0,                 # Number of epochs to wait before resuming normal operation after LR has been reduced\n    min_lr=1e-6                 # Lower bound on the learning rate\n)","metadata":{"papermill":{"duration":645.298148,"end_time":"2024-11-18T15:04:25.412141","exception":false,"start_time":"2024-11-18T14:53:40.113993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:37:08.696758Z","iopub.execute_input":"2024-11-20T18:37:08.697015Z","iopub.status.idle":"2024-11-20T18:37:08.703110Z","shell.execute_reply.started":"2024-11-20T18:37:08.696992Z","shell.execute_reply":"2024-11-20T18:37:08.702222Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import wandb\n\nwandb.login(\n    # set the wandb project where this run will be logged\n#     project= \"PolypSegment\", \n    key = \"e02f7703b40a2b3e0ab4801d4cb1d86b3b7327a6\",\n)\n\nwandb.init(\n    project=\"PolypSegment\",\n    config={\n        \"init_learning_rate\": learning_rate,\n        \"batch_size\": batch_size,\n        \"optimizer\": \"Adam\",\n        \"loss_functions\": [\"CrossEntropy\", \"Dice\"],\n        \"alpha\": alpha\n    }\n)\n\n# Add the model to WandB\nwandb.watch(model, log=\"all\")","metadata":{"execution":{"iopub.status.busy":"2024-11-20T18:37:08.704067Z","iopub.execute_input":"2024-11-20T18:37:08.704374Z","iopub.status.idle":"2024-11-20T18:37:38.532207Z","shell.execute_reply.started":"2024-11-20T18:37:08.704345Z","shell.execute_reply":"2024-11-20T18:37:38.531221Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtu7pham7\u001b[0m (\u001b[33mhustcollab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.18.7 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.12"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20241120_183710-g02a747d</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/hustcollab/PolypSegment/runs/g02a747d' target=\"_blank\">stoic-water-25</a></strong> to <a href='https://wandb.ai/hustcollab/PolypSegment' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/hustcollab/PolypSegment' target=\"_blank\">https://wandb.ai/hustcollab/PolypSegment</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/hustcollab/PolypSegment/runs/g02a747d' target=\"_blank\">https://wandb.ai/hustcollab/PolypSegment/runs/g02a747d</a>"},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"[]"},"metadata":{}}]},{"cell_type":"code","source":"num_epochs = 25\nepoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n\nfor epoch in range(num_epochs):\n    model.train()\n    train_loss = 0\n    for images, labels in train_loader:\n        images = images.to(device)\n        labels = labels.to(device)\n\n        labels = labels.squeeze(dim=1).long()\n        outputs = model(images)\n    \n        loss_ce = criterion_ce(outputs, labels)\n        loss_dice = criterion_dice(outputs, labels)\n        loss = alpha * loss_ce + (1 - alpha) * loss_dice\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        train_loss += loss.item()\n        \n#         del images, labels, outputs, loss\n#         torch.cuda.empty_cache()\n        \n    model.eval()\n    with torch.no_grad():\n        val_loss = 0\n        for images, labels in val_loader:\n            images = images.to(device)\n            labels = labels.to(device)\n            labels = labels.squeeze(dim=1).long()\n            \n            outputs = model(images)\n\n            val_loss += criterion_dice(outputs.float(),labels.long()).item()\n            \n#             del images, labels, outputs\n#             torch.cuda.empty_cache()\n            \n    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        checkpoint = { \n            'epoch': epoch,\n            'model': model.state_dict(),\n            'optimizer': optimizer.state_dict(),\n            'loss': val_loss,\n        }\n        save_path = f'model.pth'\n        torch.save(checkpoint, save_path)\n        \n    scheduler.step(val_loss)\n    epoch_bar.update(1)\n    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader)})\nepoch_bar.close()","metadata":{"papermill":{"duration":645.298148,"end_time":"2024-11-18T15:04:25.412141","exception":false,"start_time":"2024-11-18T14:53:40.113993","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:47:08.672012Z","iopub.execute_input":"2024-11-20T18:47:08.672765Z","iopub.status.idle":"2024-11-20T19:30:36.644317Z","shell.execute_reply.started":"2024-11-20T18:47:08.672730Z","shell.execute_reply":"2024-11-20T19:30:36.643539Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stderr","text":"Total Progress:   0%|          | 0/25 [00:00<?, ?it/s]","output_type":"stream"},{"name":"stdout","text":"Epoch [1/25], Loss: 0.0645475425\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:   4%|▍         | 1/25 [01:45<42:14, 105.60s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [2/25], Loss: 0.0536414395\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:   8%|▊         | 2/25 [03:29<40:06, 104.64s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [3/25], Loss: 0.0452362081\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  12%|█▏        | 3/25 [05:14<38:20, 104.58s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [4/25], Loss: 0.0418191334\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  16%|█▌        | 4/25 [06:59<36:42, 104.87s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [5/25], Loss: 0.0373047348\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  20%|██        | 5/25 [08:44<34:59, 104.99s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [6/25], Loss: 0.0334124264\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  24%|██▍       | 6/25 [10:29<33:13, 104.90s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [7/25], Loss: 0.0328275489\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  28%|██▊       | 7/25 [12:13<31:25, 104.73s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [8/25], Loss: 0.0294407021\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  32%|███▏      | 8/25 [13:58<29:40, 104.75s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [9/25], Loss: 0.0284969024\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  36%|███▌      | 9/25 [15:43<27:54, 104.68s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [10/25], Loss: 0.0275730642\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  40%|████      | 10/25 [17:28<26:12, 104.81s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [11/25], Loss: 0.0240441484\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  48%|████▊     | 12/25 [20:56<22:38, 104.52s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [12/25], Loss: 0.0246858831\nEpoch [13/25], Loss: 0.0231482735\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  52%|█████▏    | 13/25 [22:41<20:52, 104.42s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [14/25], Loss: 0.0228800215\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  56%|█████▌    | 14/25 [24:24<19:06, 104.23s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [15/25], Loss: 0.0220962231\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  60%|██████    | 15/25 [26:09<17:22, 104.28s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [16/25], Loss: 0.0198844164\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  68%|██████▊   | 17/25 [29:38<13:56, 104.50s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [17/25], Loss: 0.0243116168\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  72%|███████▏  | 18/25 [31:22<12:09, 104.17s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [18/25], Loss: 0.0207303856\nEpoch [19/25], Loss: 0.0181293575\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  80%|████████  | 20/25 [34:50<08:40, 104.10s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [20/25], Loss: 0.0182054473\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  84%|████████▍ | 21/25 [36:33<06:55, 103.92s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [21/25], Loss: 0.0204908113\nEpoch [22/25], Loss: 0.0160256995\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  92%|█████████▏| 23/25 [40:01<03:27, 103.78s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [23/25], Loss: 0.0161220210\n","output_type":"stream"},{"name":"stderr","text":"Total Progress:  96%|█████████▌| 24/25 [41:44<01:43, 103.63s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [24/25], Loss: 0.0192296287\n","output_type":"stream"},{"name":"stderr","text":"Total Progress: 100%|██████████| 25/25 [43:27<00:00, 104.32s/it]","output_type":"stream"},{"name":"stdout","text":"Epoch [25/25], Loss: 0.0223425322\nEpoch 00030: reducing learning rate of group 0 to 5.0000e-05.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = smp.UnetPlusPlus(\n#     encoder_name=\"resnet34\",        \n#     encoder_weights=\"imagenet\",     \n#     in_channels=3,                  \n#     classes=3     \n# )\ncheckpoint = torch.load('/kaggle/working/model.pth')\nmodel.load_state_dict(checkpoint['model'])\nmodel.to(device)","metadata":{"papermill":{"duration":0.027955,"end_time":"2024-11-18T15:04:25.461477","exception":false,"start_time":"2024-11-18T15:04:25.433522","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T19:31:33.370731Z","iopub.execute_input":"2024-11-20T19:31:33.371698Z","iopub.status.idle":"2024-11-20T19:31:33.622254Z","shell.execute_reply.started":"2024-11-20T19:31:33.371662Z","shell.execute_reply":"2024-11-20T19:31:33.621251Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"UnetPlusPlus(\n  (encoder): ResNetEncoder(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (5): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (decoder): UnetPlusPlusDecoder(\n    (center): Identity()\n    (blocks): ModuleDict(\n      (x_0_0): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_1): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(320, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_2): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(320, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_1_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_2_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_3_3): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n      (x_0_4): DecoderBlock(\n        (conv1): Conv2dReLU(\n          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention1): Attention(\n          (attention): Identity()\n        )\n        (conv2): Conv2dReLU(\n          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n          (2): ReLU(inplace=True)\n        )\n        (attention2): Attention(\n          (attention): Identity()\n        )\n      )\n    )\n  )\n  (segmentation_head): SegmentationHead(\n    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (1): Identity()\n    (2): Activation(\n      (activation): Identity()\n    )\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"!mkdir prediction","metadata":{"papermill":{"duration":1.083851,"end_time":"2024-11-18T15:04:26.566165","exception":false,"start_time":"2024-11-18T15:04:25.482314","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T19:31:44.902912Z","iopub.execute_input":"2024-11-20T19:31:44.903276Z","iopub.status.idle":"2024-11-20T19:31:45.975185Z","shell.execute_reply.started":"2024-11-20T19:31:44.903233Z","shell.execute_reply":"2024-11-20T19:31:45.973976Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stdout","text":"mkdir: cannot create directory ‘prediction’: File exists\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Get Testset Prediction","metadata":{}},{"cell_type":"code","source":"model.eval()\nfor i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n    ori_img = cv2.imread(img_path)\n    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n    ori_h = ori_img.shape[0]\n    ori_w = ori_img.shape[1]\n    img = cv2.resize(ori_img, img_resize, interpolation=cv2.INTER_AREA)\n    transformed = val_transformation(image=img)\n    input_img = transformed[\"image\"]\n    input_img = input_img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output_mask = model(input_img).squeeze(0).cpu().numpy().transpose(1, 2, 0)\n    mask = cv2.resize(output_mask, (ori_w, ori_h), interpolation=cv2.INTER_CUBIC)\n    mask = np.argmax(mask, axis=2)\n    mask_rgb = mask_to_rgb(mask, color_dict)\n    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb)\n    # Clear variables to free memory\n    del img, input_img, output_mask, mask, mask_rgb\n    torch.cuda.empty_cache()","metadata":{"papermill":{"duration":24.769309,"end_time":"2024-11-18T15:04:51.356898","exception":false,"start_time":"2024-11-18T15:04:26.587589","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T19:31:49.338885Z","iopub.execute_input":"2024-11-20T19:31:49.339648Z","iopub.status.idle":"2024-11-20T19:32:16.446874Z","shell.execute_reply.started":"2024-11-20T19:31:49.339614Z","shell.execute_reply":"2024-11-20T19:32:16.445829Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    \n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/prediction'\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"papermill":{"duration":3.010263,"end_time":"2024-11-18T15:04:54.388516","exception":false,"start_time":"2024-11-18T15:04:51.378253","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T19:32:16.448745Z","iopub.execute_input":"2024-11-20T19:32:16.449131Z","iopub.status.idle":"2024-11-20T19:32:19.407060Z","shell.execute_reply.started":"2024-11-20T19:32:16.449092Z","shell.execute_reply":"2024-11-20T19:32:19.406066Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"/kaggle/working/prediction/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n/kaggle/working/prediction/8fa8625605da2023387fd56c04414eaa.jpeg\n/kaggle/working/prediction/6b83ef461c2a337948a41964c1d4f50a.jpeg\n/kaggle/working/prediction/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n/kaggle/working/prediction/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n/kaggle/working/prediction/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n/kaggle/working/prediction/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n/kaggle/working/prediction/3425b976973f13dd311a65d2b46d0a60.jpeg\n/kaggle/working/prediction/e1797c77826f9a7021bab9fc73303988.jpeg\n/kaggle/working/prediction/80c643782707d7c359e27888daefee82.jpeg\n/kaggle/working/prediction/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n/kaggle/working/prediction/63b8318ecf467d7ad048df39beb17636.jpeg\n/kaggle/working/prediction/d694539ef2424a9218697283baa3657e.jpeg\n/kaggle/working/prediction/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n/kaggle/working/prediction/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n/kaggle/working/prediction/c41545ba55aadaa77712a48e11d579d9.jpeg\n/kaggle/working/prediction/6ad1468996b4a9ce6d840b53a6558038.jpeg\n/kaggle/working/prediction/318ecf467d7ad048df39beb176363408.jpeg\n/kaggle/working/prediction/88e16d4ca6160127cd1d5ff99c267599.jpeg\n/kaggle/working/prediction/26679bff55177a34fc01019eec999fd8.jpeg\n/kaggle/working/prediction/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n/kaggle/working/prediction/268d4b4ef4d95ceea11957998906d369.jpeg\n/kaggle/working/prediction/4f437f0019f7e6af7d7147763bdfb928.jpeg\n/kaggle/working/prediction/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n/kaggle/working/prediction/692195f853af7f8a4df1ec859759b7c8.jpeg\n/kaggle/working/prediction/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n/kaggle/working/prediction/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n/kaggle/working/prediction/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n/kaggle/working/prediction/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n/kaggle/working/prediction/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n/kaggle/working/prediction/3dd311a65d2b46d0a6085835c525af63.jpeg\n/kaggle/working/prediction/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n/kaggle/working/prediction/998906d3694abb47953b0e4909384b57.jpeg\n/kaggle/working/prediction/c193ac8d551c149b60f2965341caf528.jpeg\n/kaggle/working/prediction/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n/kaggle/working/prediction/6679bff55177a34fc01019eec999fd84.jpeg\n/kaggle/working/prediction/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n/kaggle/working/prediction/2ed9fbb63b28163a745959c03983064a.jpeg\n/kaggle/working/prediction/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n/kaggle/working/prediction/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n/kaggle/working/prediction/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n/kaggle/working/prediction/68d4b4ef4d95ceea11957998906d3694.jpeg\n/kaggle/working/prediction/1531871f2fd85a04faeeb2b535797395.jpeg\n/kaggle/working/prediction/ea42b4eebc9e5a87e443434ac60af150.jpeg\n/kaggle/working/prediction/dd094a7f32574d6c748c41743c6c08a1.jpeg\n/kaggle/working/prediction/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n/kaggle/working/prediction/df366e057db382b8564872a27301a654.jpeg\n/kaggle/working/prediction/4417fda8019410b1fcf0625f608b4ce9.jpeg\n/kaggle/working/prediction/b21960c94b0aab4c024a573c692195f8.jpeg\n/kaggle/working/prediction/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n/kaggle/working/prediction/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n/kaggle/working/prediction/7fda8019410b1fcf0625f608b4ce9762.jpeg\n/kaggle/working/prediction/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n/kaggle/working/prediction/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n/kaggle/working/prediction/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n/kaggle/working/prediction/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n/kaggle/working/prediction/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n/kaggle/working/prediction/e9082ea2c193ac8d551c149b60f29653.jpeg\n/kaggle/working/prediction/ff55177a34fc01019eec999fd84e679b.jpeg\n/kaggle/working/prediction/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n/kaggle/working/prediction/a51625559c7e610b1531871f2fd85a04.jpeg\n/kaggle/working/prediction/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n/kaggle/working/prediction/87133b51209db6dcdda5cc8a788edaeb.jpeg\n/kaggle/working/prediction/7af2ed9fbb63b28163a745959c039830.jpeg\n/kaggle/working/prediction/936de314f2d95e6c487ffa651b477422.jpeg\n/kaggle/working/prediction/85a04faeeb2b535797395305af926a6f.jpeg\n/kaggle/working/prediction/cb1b387133b51209db6dcdda5cc8a788.jpeg\n/kaggle/working/prediction/710d568df17586ad8f3297c819c90895.jpeg\n/kaggle/working/prediction/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n/kaggle/working/prediction/82ea2c193ac8d551c149b60f2965341c.jpeg\n/kaggle/working/prediction/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n/kaggle/working/prediction/45b21960c94b0aab4c024a573c692195.jpeg\n/kaggle/working/prediction/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n/kaggle/working/prediction/4ef4d95ceea11957998906d3694abb47.jpeg\n/kaggle/working/prediction/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n/kaggle/working/prediction/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n/kaggle/working/prediction/54ba59c7de13a35276a476420655433a.jpeg\n/kaggle/working/prediction/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n/kaggle/working/prediction/cc5cfd263f1f90be28799235026b3550.jpeg\n/kaggle/working/prediction/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n/kaggle/working/prediction/afe1f119f21b248d152b672ab3492fc6.jpeg\n/kaggle/working/prediction/4ca6160127cd1d5ff99c267599fc487b.jpeg\n/kaggle/working/prediction/c5a0808bee60b246359c68c836f843dc.jpeg\n/kaggle/working/prediction/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n/kaggle/working/prediction/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n/kaggle/working/prediction/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n/kaggle/working/prediction/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n/kaggle/working/prediction/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n/kaggle/working/prediction/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n/kaggle/working/prediction/285e26c90e1797c77826f9a7021bab9f.jpeg\n/kaggle/working/prediction/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n/kaggle/working/prediction/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n/kaggle/working/prediction/cf6644589e532a9ee954f81faedbce39.jpeg\n/kaggle/working/prediction/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n/kaggle/working/prediction/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n/kaggle/working/prediction/e4a17af18f72c8e6166a915669c99390.jpeg\n/kaggle/working/prediction/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n/kaggle/working/prediction/50534bca540e24f489284b8e6953ad88.jpeg\n/kaggle/working/prediction/66e057db382b8564872a27301a654864.jpeg\n/kaggle/working/prediction/3c692195f853af7f8a4df1ec859759b7.jpeg\n/kaggle/working/prediction/391adc0bb223c4eaf3372eae567c94ea.jpeg\n/kaggle/working/prediction/39dda50f954ba59c7de13a35276a4764.jpeg\n/kaggle/working/prediction/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n/kaggle/working/prediction/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n/kaggle/working/prediction/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n/kaggle/working/prediction/559c7e610b1531871f2fd85a04faeeb2.jpeg\n/kaggle/working/prediction/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n/kaggle/working/prediction/aeeb2b535797395305af926a6f23c5d6.jpeg\n/kaggle/working/prediction/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n/kaggle/working/prediction/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n/kaggle/working/prediction/be4d18d5401f659532897255ce2dd4ae.jpeg\n/kaggle/working/prediction/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n/kaggle/working/prediction/fb905b78a91391adc0bb223c4eaf3372.jpeg\n/kaggle/working/prediction/41ed86e58224cb76a67d4dcf9596154e.jpeg\n/kaggle/working/prediction/782707d7c359e27888daefee82519763.jpeg\n/kaggle/working/prediction/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n/kaggle/working/prediction/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n/kaggle/working/prediction/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n/kaggle/working/prediction/f13dd311a65d2b46d0a6085835c525af.jpeg\n/kaggle/working/prediction/d3694abb47953b0e4909384b57bb6a05.jpeg\n/kaggle/working/prediction/7f0019f7e6af7d7147763bdfb928d788.jpeg\n/kaggle/working/prediction/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n/kaggle/working/prediction/8cbdf366e057db382b8564872a27301a.jpeg\n/kaggle/working/prediction/1db239dda50f954ba59c7de13a35276a.jpeg\n/kaggle/working/prediction/e73749a0d21db70dd094a7f32574d6c7.jpeg\n/kaggle/working/prediction/5026b3550534bca540e24f489284b8e6.jpeg\n/kaggle/working/prediction/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n/kaggle/working/prediction/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n/kaggle/working/prediction/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n/kaggle/working/prediction/d077bad31c8c5f54ffaa27a623511c38.jpeg\n/kaggle/working/prediction/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n/kaggle/working/prediction/425b976973f13dd311a65d2b46d0a608.jpeg\n/kaggle/working/prediction/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n/kaggle/working/prediction/019410b1fcf0625f608b4ce97629ab55.jpeg\n/kaggle/working/prediction/5a51625559c7e610b1531871f2fd85a0.jpeg\n/kaggle/working/prediction/625559c7e610b1531871f2fd85a04fae.jpeg\n/kaggle/working/prediction/fe1f119f21b248d152b672ab3492fc62.jpeg\n/kaggle/working/prediction/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n/kaggle/working/prediction/0a0317371a966bf4b3466463a3c64db1.jpeg\n/kaggle/working/prediction/626650908b1cb932a767bf5487ced51b.jpeg\n/kaggle/working/prediction/5beb48f0be11d0309d1dff09b8405734.jpeg\n/kaggle/working/prediction/13dd311a65d2b46d0a6085835c525af6.jpeg\n/kaggle/working/prediction/c4be73749a0d21db70dd094a7f32574d.jpeg\n/kaggle/working/prediction/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n/kaggle/working/prediction/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n/kaggle/working/prediction/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n/kaggle/working/prediction/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n/kaggle/working/prediction/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n/kaggle/working/prediction/7936140a2d5fc1443c4e445927738677.jpeg\n/kaggle/working/prediction/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n/kaggle/working/prediction/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n/kaggle/working/prediction/a9d45c3dbc695325ded465efde988dfb.jpeg\n/kaggle/working/prediction/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n/kaggle/working/prediction/67d4dcf9596154efb7cef748d9cbd617.jpeg\n/kaggle/working/prediction/80cae6daedd989517cb8041ed86e5822.jpeg\n/kaggle/working/prediction/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n/kaggle/working/prediction/71f2fd85a04faeeb2b535797395305af.jpeg\n/kaggle/working/prediction/05b78a91391adc0bb223c4eaf3372eae.jpeg\n/kaggle/working/prediction/c22268d4b4ef4d95ceea11957998906d.jpeg\n/kaggle/working/prediction/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n/kaggle/working/prediction/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n/kaggle/working/prediction/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n/kaggle/working/prediction/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n/kaggle/working/prediction/4baddc22268d4b4ef4d95ceea1195799.jpeg\n/kaggle/working/prediction/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n/kaggle/working/prediction/b70dd094a7f32574d6c748c41743c6c0.jpeg\n/kaggle/working/prediction/e3c84417fda8019410b1fcf0625f608b.jpeg\n/kaggle/working/prediction/3bbc04a3afe1f119f21b248d152b672a.jpeg\n/kaggle/working/prediction/6d3694abb47953b0e4909384b57bb6a0.jpeg\n/kaggle/working/prediction/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n/kaggle/working/prediction/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n/kaggle/working/prediction/5b21960c94b0aab4c024a573c692195f.jpeg\n/kaggle/working/prediction/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n/kaggle/working/prediction/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n/kaggle/working/prediction/3b8318ecf467d7ad048df39beb176363.jpeg\n/kaggle/working/prediction/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n/kaggle/working/prediction/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n/kaggle/working/prediction/e19769fa2d37d32780fd497e1c0e9082.jpeg\n/kaggle/working/prediction/be86f03d900fd197cd955fa095f97845.jpeg\n/kaggle/working/prediction/461c2a337948a41964c1d4f50a5f3601.jpeg\n/kaggle/working/prediction/c695325ded465efde988dfb96d081533.jpeg\n/kaggle/working/prediction/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n/kaggle/working/prediction/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n/kaggle/working/prediction/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n/kaggle/working/prediction/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n/kaggle/working/prediction/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n/kaggle/working/prediction/aafac813fe3ccba3e032dd2948a80c64.jpeg\n/kaggle/working/prediction/77e004e8bfb905b78a91391adc0bb223.jpeg\n/kaggle/working/prediction/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n/kaggle/working/prediction/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n/kaggle/working/prediction/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n/kaggle/working/prediction/9c7976c1182df0de51d32128c358d1fd.jpeg\n/kaggle/working/prediction/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n/kaggle/working/prediction/60b246359c68c836f843dcf41f4dce3c.jpeg\n/kaggle/working/prediction/3c84417fda8019410b1fcf0625f608b4.jpeg\n/kaggle/working/prediction/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n/kaggle/working/prediction/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n/kaggle/working/prediction/05734fbeedd0f9da760db74a29abdb04.jpeg\n/kaggle/working/prediction/dd78294679c9cbb2a365b5574868eb60.jpeg\n/kaggle/working/prediction/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Inference","metadata":{"papermill":{"duration":0.022476,"end_time":"2024-11-18T15:04:54.434123","exception":false,"start_time":"2024-11-18T15:04:54.411647","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# from torch.jit import load\n# model = UNet()\n# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n\n# checkpoint = torch.load(pretrained_path)","metadata":{"papermill":{"duration":0.028972,"end_time":"2024-11-18T15:04:54.485244","exception":false,"start_time":"2024-11-18T15:04:54.456272","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:47:02.232053Z","iopub.execute_input":"2024-11-20T18:47:02.232495Z","iopub.status.idle":"2024-11-20T18:47:02.237810Z","shell.execute_reply.started":"2024-11-20T18:47:02.232441Z","shell.execute_reply":"2024-11-20T18:47:02.236646Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# optimizer.load_state_dict(checkpoint['optimizer'])","metadata":{"papermill":{"duration":0.028595,"end_time":"2024-11-18T15:04:54.536070","exception":false,"start_time":"2024-11-18T15:04:54.507475","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:47:02.239126Z","iopub.execute_input":"2024-11-20T18:47:02.239423Z","iopub.status.idle":"2024-11-20T18:47:02.254235Z","shell.execute_reply.started":"2024-11-20T18:47:02.239400Z","shell.execute_reply":"2024-11-20T18:47:02.253392Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"# from collections import OrderedDict\n# new_state_dict = OrderedDict()\n# for k, v in checkpoint['model'].items():\n#     name = k[7:] # remove `module.`\n#     new_state_dict[name] = v\n# # load params\n# model.load_state_dict(new_state_dict)","metadata":{"papermill":{"duration":0.02903,"end_time":"2024-11-18T15:04:54.587222","exception":false,"start_time":"2024-11-18T15:04:54.558192","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-11-20T18:47:02.255457Z","iopub.execute_input":"2024-11-20T18:47:02.255858Z","iopub.status.idle":"2024-11-20T18:47:02.270053Z","shell.execute_reply.started":"2024-11-20T18:47:02.255826Z","shell.execute_reply":"2024-11-20T18:47:02.268894Z"},"trusted":true},"execution_count":27,"outputs":[]}]}