{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "454c8bd2",
   "metadata": {
    "papermill": {
     "duration": 0.006294,
     "end_time": "2024-11-22T07:58:22.754722",
     "exception": false,
     "start_time": "2024-11-22T07:58:22.748428",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d54650",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:58:22.767602Z",
     "iopub.status.busy": "2024-11-22T07:58:22.767280Z",
     "iopub.status.idle": "2024-11-22T07:58:56.453515Z",
     "shell.execute_reply": "2024-11-22T07:58:56.452402Z"
    },
    "papermill": {
     "duration": 33.69448,
     "end_time": "2024-11-22T07:58:56.455215",
     "exception": false,
     "start_time": "2024-11-22T07:58:22.760735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torchsummary\r\n",
      "  Obtaining dependency information for torchsummary from https://files.pythonhosted.org/packages/7d/18/1474d06f721b86e6a9b9d7392ad68bed711a02f3b61ac43f13c719db50a6/torchsummary-1.5.1-py3-none-any.whl.metadata\r\n",
      "  Downloading torchsummary-1.5.1-py3-none-any.whl.metadata (296 bytes)\r\n",
      "Downloading torchsummary-1.5.1-py3-none-any.whl (2.8 kB)\r\n",
      "Installing collected packages: torchsummary\r\n",
      "Successfully installed torchsummary-1.5.1\r\n",
      "Collecting torchgeometry\r\n",
      "  Obtaining dependency information for torchgeometry from https://files.pythonhosted.org/packages/a6/d6/3f6820c0589bc3876080c59b58a3bad11af746a7b46f364b1cde7972bd72/torchgeometry-0.1.2-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading torchgeometry-0.1.2-py2.py3-none-any.whl.metadata (2.9 kB)\r\n",
      "Requirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from torchgeometry) (2.0.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.12.2)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (4.5.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->torchgeometry) (3.1.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->torchgeometry) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->torchgeometry) (1.3.0)\r\n",
      "Downloading torchgeometry-0.1.2-py2.py3-none-any.whl (42 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: torchgeometry\r\n",
      "Successfully installed torchgeometry-0.1.2\r\n",
      "Collecting segmentation-models-pytorch\r\n",
      "  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/54/dd/0a3417eebc791d1f60ba9949a2c6fcb406ba671c67042179fb270409b17b/segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata\r\n",
      "  Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl.metadata (30 kB)\r\n",
      "Collecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\r\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\r\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hCollecting huggingface-hub>=0.24.6 (from segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for huggingface-hub>=0.24.6 from https://files.pythonhosted.org/packages/60/bf/cea0b9720c32fa01b0c4ec4b16b9f4ae34ca106b202ebbae9f03ab98cd8f/huggingface_hub-0.26.2-py3-none-any.whl.metadata\r\n",
      "  Downloading huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\r\n",
      "Collecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\r\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (1.16.0)\r\n",
      "Collecting timm==0.9.7 (from segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for timm==0.9.7 from https://files.pythonhosted.org/packages/7a/bd/2c56be7a3b5bc71cf85a405246b89d5359f942c9f7fb6db6306d9d056092/timm-0.9.7-py3-none-any.whl.metadata\r\n",
      "  Downloading timm-0.9.7-py3-none-any.whl.metadata (58 kB)\r\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\r\n",
      "Collecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\r\n",
      "  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\r\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (6.0.1)\r\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.7->segmentation-models-pytorch) (0.4.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.12.2)\r\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.10.0)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (21.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.24.6->segmentation-models-pytorch) (4.5.0)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.0.9)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.2.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.24.6->segmentation-models-pytorch) (2023.7.22)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\r\n",
      "Downloading segmentation_models_pytorch-0.3.4-py3-none-any.whl (109 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading timm-0.9.7-py3-none-any.whl (2.2 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading huggingface_hub-0.26.2-py3-none-any.whl (447 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m447.5/447.5 kB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\r\n",
      "Building wheels for collected packages: efficientnet-pytorch, pretrainedmodels\r\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=2cd4ace1ca15c3adcd58c48d74af7872fb29a917ce4f3e4f14ea8ac4991f99c9\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\r\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=3c67cc3bc186d6c476b3580c4c46784c35ad82a946057cc350aec65ab1a70b0d\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\r\n",
      "Successfully built efficientnet-pytorch pretrainedmodels\r\n",
      "Installing collected packages: munch, huggingface-hub, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\r\n",
      "  Attempting uninstall: huggingface-hub\r\n",
      "    Found existing installation: huggingface-hub 0.17.3\r\n",
      "    Uninstalling huggingface-hub-0.17.3:\r\n",
      "      Successfully uninstalled huggingface-hub-0.17.3\r\n",
      "  Attempting uninstall: timm\r\n",
      "    Found existing installation: timm 0.9.10\r\n",
      "    Uninstalling timm-0.9.10:\r\n",
      "      Successfully uninstalled timm-0.9.10\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tokenizers 0.14.1 requires huggingface_hub<0.18,>=0.16.4, but you have huggingface-hub 0.26.2 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed efficientnet-pytorch-0.7.1 huggingface-hub-0.26.2 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.4 timm-0.9.7\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n",
    "!pip install torchgeometry\n",
    "%pip install -U segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194e15c8",
   "metadata": {
    "papermill": {
     "duration": 0.007921,
     "end_time": "2024-11-22T07:58:56.471192",
     "exception": false,
     "start_time": "2024-11-22T07:58:56.463271",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f09c912",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-22T07:58:56.489075Z",
     "iopub.status.busy": "2024-11-22T07:58:56.488777Z",
     "iopub.status.idle": "2024-11-22T07:59:05.550438Z",
     "shell.execute_reply": "2024-11-22T07:59:05.549554Z"
    },
    "papermill": {
     "duration": 9.073439,
     "end_time": "2024-11-22T07:59:05.552469",
     "exception": false,
     "start_time": "2024-11-22T07:58:56.479030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "from torchinfo import summary\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31f683c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:05.570095Z",
     "iopub.status.busy": "2024-11-22T07:59:05.569519Z",
     "iopub.status.idle": "2024-11-22T07:59:06.601396Z",
     "shell.execute_reply": "2024-11-22T07:59:06.600257Z"
    },
    "papermill": {
     "duration": 1.042737,
     "end_time": "2024-11-22T07:59:06.603417",
     "exception": false,
     "start_time": "2024-11-22T07:59:05.560680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-122f3caa-91ba-1f39-6a1a-d2f7a7ebda4d)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69d02ec9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:06.621773Z",
     "iopub.status.busy": "2024-11-22T07:59:06.621398Z",
     "iopub.status.idle": "2024-11-22T07:59:06.680948Z",
     "shell.execute_reply": "2024-11-22T07:59:06.680069Z"
    },
    "papermill": {
     "duration": 0.070705,
     "end_time": "2024-11-22T07:59:06.682562",
     "exception": false,
     "start_time": "2024-11-22T07:59:06.611857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a618c1",
   "metadata": {
    "papermill": {
     "duration": 0.008027,
     "end_time": "2024-11-22T07:59:06.698842",
     "exception": false,
     "start_time": "2024-11-22T07:59:06.690815",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d261f3ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:06.716073Z",
     "iopub.status.busy": "2024-11-22T07:59:06.715579Z",
     "iopub.status.idle": "2024-11-22T07:59:08.767166Z",
     "shell.execute_reply": "2024-11-22T07:59:08.766142Z"
    },
    "papermill": {
     "duration": 2.062344,
     "end_time": "2024-11-22T07:59:08.768987",
     "exception": false,
     "start_time": "2024-11-22T07:59:06.706643",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6290deb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:08.787022Z",
     "iopub.status.busy": "2024-11-22T07:59:08.786306Z",
     "iopub.status.idle": "2024-11-22T07:59:08.790390Z",
     "shell.execute_reply": "2024-11-22T07:59:08.789757Z"
    },
    "papermill": {
     "duration": 0.014678,
     "end_time": "2024-11-22T07:59:08.792037",
     "exception": false,
     "start_time": "2024-11-22T07:59:08.777359",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def calculate_mean_image_size(image_dir):\n",
    "#     widths = []\n",
    "#     heights = []\n",
    "\n",
    "#     for filename in os.listdir(image_dir):\n",
    "#         if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "#             img_path = os.path.join(image_dir, filename)\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 h, w = image.shape[:2]\n",
    "#                 heights.append(h)\n",
    "#                 widths.append(w)\n",
    "#             else:\n",
    "#                 print(f\"Warning: Unable to read image {img_path}\")\n",
    "\n",
    "#     mean_width = int(np.mean(widths))\n",
    "#     mean_height = int(np.mean(heights))\n",
    "#     median_width = int(np.median(widths))\n",
    "#     median_height = int(np.median(heights))\n",
    "\n",
    "#     print(f\"Number of images: {len(widths)}\")\n",
    "#     print(f\"Mean Width: {mean_width}, Mean Height: {mean_height}\")\n",
    "#     print(f\"Median Width: {median_width}, Median Height: {median_height}\")\n",
    "\n",
    "#     return mean_width, mean_height, widths, heights\n",
    "\n",
    "# # Example usage:\n",
    "# image_directory = '/kaggle/input/bkai-igh-neopolyp/test/test'\n",
    "# mean_w, mean_h, widths, heights = calculate_mean_image_size(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db716a99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:08.809213Z",
     "iopub.status.busy": "2024-11-22T07:59:08.808991Z",
     "iopub.status.idle": "2024-11-22T07:59:08.812491Z",
     "shell.execute_reply": "2024-11-22T07:59:08.811777Z"
    },
    "papermill": {
     "duration": 0.014088,
     "end_time": "2024-11-22T07:59:08.814129",
     "exception": false,
     "start_time": "2024-11-22T07:59:08.800041",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_dimension_distribution(widths, heights):\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.hist(widths, bins=20, color='skyblue')\n",
    "#     plt.title('Width Distribution')\n",
    "#     plt.xlabel('Width')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.hist(heights, bins=20, color='salmon')\n",
    "#     plt.title('Height Distribution')\n",
    "#     plt.xlabel('Height')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # After collecting widths and heights in the function above:\n",
    "# plot_dimension_distribution(widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c107f41e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:08.873515Z",
     "iopub.status.busy": "2024-11-22T07:59:08.873185Z",
     "iopub.status.idle": "2024-11-22T07:59:10.969508Z",
     "shell.execute_reply": "2024-11-22T07:59:10.968686Z"
    },
    "papermill": {
     "duration": 2.148976,
     "end_time": "2024-11-22T07:59:10.971398",
     "exception": false,
     "start_time": "2024-11-22T07:59:08.822422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c121d221",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:10.990316Z",
     "iopub.status.busy": "2024-11-22T07:59:10.990041Z",
     "iopub.status.idle": "2024-11-22T07:59:10.998826Z",
     "shell.execute_reply": "2024-11-22T07:59:10.998142Z"
    },
    "papermill": {
     "duration": 0.020151,
     "end_time": "2024-11-22T07:59:11.000333",
     "exception": false,
     "start_time": "2024-11-22T07:59:10.980182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DatasetCustom(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b790cb03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.018220Z",
     "iopub.status.busy": "2024-11-22T07:59:11.017971Z",
     "iopub.status.idle": "2024-11-22T07:59:11.021615Z",
     "shell.execute_reply": "2024-11-22T07:59:11.020972Z"
    },
    "papermill": {
     "duration": 0.014571,
     "end_time": "2024-11-22T07:59:11.023189",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.008618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = (256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "029fca03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.040548Z",
     "iopub.status.busy": "2024-11-22T07:59:11.040290Z",
     "iopub.status.idle": "2024-11-22T07:59:11.044894Z",
     "shell.execute_reply": "2024-11-22T07:59:11.044279Z"
    },
    "papermill": {
     "duration": 0.015186,
     "end_time": "2024-11-22T07:59:11.046408",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.031222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = DatasetCustom(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= img_resize,\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f51c9e",
   "metadata": {
    "papermill": {
     "duration": 0.00789,
     "end_time": "2024-11-22T07:59:11.062462",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.054572",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b8a8438e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.079634Z",
     "iopub.status.busy": "2024-11-22T07:59:11.079370Z",
     "iopub.status.idle": "2024-11-22T07:59:11.084602Z",
     "shell.execute_reply": "2024-11-22T07:59:11.083922Z"
    },
    "papermill": {
     "duration": 0.015701,
     "end_time": "2024-11-22T07:59:11.086242",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.070541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AugmentDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, length_multiplier=1):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.length_multiplier = length_multiplier\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx % len(self.dataset)\n",
    "        image, label = self.dataset[actual_idx]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * self.length_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a38b56f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.103630Z",
     "iopub.status.busy": "2024-11-22T07:59:11.103380Z",
     "iopub.status.idle": "2024-11-22T07:59:11.108998Z",
     "shell.execute_reply": "2024-11-22T07:59:11.108340Z"
    },
    "papermill": {
     "duration": 0.016188,
     "end_time": "2024-11-22T07:59:11.110686",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.094498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), eps=None, always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6059bcd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.127892Z",
     "iopub.status.busy": "2024-11-22T07:59:11.127638Z",
     "iopub.status.idle": "2024-11-22T07:59:11.140018Z",
     "shell.execute_reply": "2024-11-22T07:59:11.139446Z"
    },
    "papermill": {
     "duration": 0.02281,
     "end_time": "2024-11-22T07:59:11.141595",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.118785",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 32\n",
    "# Randomly split the dataset\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "\n",
    "train_dataset = AugmentDataset(train_dataset, transform=train_transformation, length_multiplier=2)\n",
    "val_dataset = AugmentDataset(val_dataset, transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c66afe5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.158653Z",
     "iopub.status.busy": "2024-11-22T07:59:11.158406Z",
     "iopub.status.idle": "2024-11-22T07:59:11.163384Z",
     "shell.execute_reply": "2024-11-22T07:59:11.162483Z"
    },
    "papermill": {
     "duration": 0.015445,
     "end_time": "2024-11-22T07:59:11.165016",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.149571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66839a3a",
   "metadata": {
    "papermill": {
     "duration": 0.008004,
     "end_time": "2024-11-22T07:59:11.181239",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.173235",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cac1227b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:11.198661Z",
     "iopub.status.busy": "2024-11-22T07:59:11.198436Z",
     "iopub.status.idle": "2024-11-22T07:59:12.105635Z",
     "shell.execute_reply": "2024-11-22T07:59:12.104755Z"
    },
    "papermill": {
     "duration": 0.918369,
     "end_time": "2024-11-22T07:59:12.107789",
     "exception": false,
     "start_time": "2024-11-22T07:59:11.189420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 83.3M/83.3M [00:00<00:00, 376MB/s]\n"
     ]
    }
   ],
   "source": [
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f2d25780",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.126875Z",
     "iopub.status.busy": "2024-11-22T07:59:12.126544Z",
     "iopub.status.idle": "2024-11-22T07:59:12.130014Z",
     "shell.execute_reply": "2024-11-22T07:59:12.129245Z"
    },
    "papermill": {
     "duration": 0.014743,
     "end_time": "2024-11-22T07:59:12.131562",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.116819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/kaggle/input/kaggle-notebook/model.pth')\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84db19ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.149639Z",
     "iopub.status.busy": "2024-11-22T07:59:12.149408Z",
     "iopub.status.idle": "2024-11-22T07:59:12.153829Z",
     "shell.execute_reply": "2024-11-22T07:59:12.153205Z"
    },
    "papermill": {
     "duration": 0.015115,
     "end_time": "2024-11-22T07:59:12.155363",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.140248",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b12f28d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.173372Z",
     "iopub.status.busy": "2024-11-22T07:59:12.173134Z",
     "iopub.status.idle": "2024-11-22T07:59:12.176416Z",
     "shell.execute_reply": "2024-11-22T07:59:12.175697Z"
    },
    "papermill": {
     "duration": 0.013967,
     "end_time": "2024-11-22T07:59:12.177957",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.163990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del dataset\n",
    "del train_dataset\n",
    "del val_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7753e4df",
   "metadata": {
    "papermill": {
     "duration": 0.008446,
     "end_time": "2024-11-22T07:59:12.194862",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.186416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00dae50",
   "metadata": {
    "papermill": {
     "duration": 0.008242,
     "end_time": "2024-11-22T07:59:12.211599",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.203357",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define Dice loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e9bc956",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.229833Z",
     "iopub.status.busy": "2024-11-22T07:59:12.229542Z",
     "iopub.status.idle": "2024-11-22T07:59:12.235877Z",
     "shell.execute_reply": "2024-11-22T07:59:12.235145Z"
    },
    "papermill": {
     "duration": 0.017344,
     "end_time": "2024-11-22T07:59:12.237516",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.220172",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class DiceLoss(nn.Module):\n",
    "    def __init__(self, num_classes=3, epsilon=1e-6):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, outputs, targets):\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        targets_one_hot = F.one_hot(targets, num_classes=self.num_classes).permute(0, 3, 1, 2).float()\n",
    "\n",
    "        # Flatten the tensors\n",
    "        outputs_flat = outputs.contiguous().view(-1, self.num_classes)\n",
    "        targets_flat = targets_one_hot.contiguous().view(-1, self.num_classes)\n",
    "\n",
    "        intersection = torch.sum(outputs_flat * targets_flat, dim=0)\n",
    "        union = torch.sum(outputs_flat + targets_flat, dim=0)\n",
    "\n",
    "        dice_loss = 1 - (2 * intersection + self.epsilon) / (union + self.epsilon)\n",
    "        mean_dice_loss = dice_loss.mean()\n",
    "\n",
    "        return mean_dice_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcdcaa0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.255783Z",
     "iopub.status.busy": "2024-11-22T07:59:12.255309Z",
     "iopub.status.idle": "2024-11-22T07:59:12.436932Z",
     "shell.execute_reply": "2024-11-22T07:59:12.435991Z"
    },
    "papermill": {
     "duration": 0.193003,
     "end_time": "2024-11-22T07:59:12.439113",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.246110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_dice = DiceLoss(num_classes=3)\n",
    "alpha = 0.5  # Weight for balancing the two losses\n",
    "best_val_loss = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079553b7",
   "metadata": {
    "papermill": {
     "duration": 0.008357,
     "end_time": "2024-11-22T07:59:12.456555",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.448198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make use of learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d93d4ec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.474656Z",
     "iopub.status.busy": "2024-11-22T07:59:12.474365Z",
     "iopub.status.idle": "2024-11-22T07:59:12.480264Z",
     "shell.execute_reply": "2024-11-22T07:59:12.479434Z"
    },
    "papermill": {
     "duration": 0.017203,
     "end_time": "2024-11-22T07:59:12.482088",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.464885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Assuming you've already defined your optimizer\n",
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize the scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',                 # We want to minimize the validation loss\n",
    "    factor=0.5,                 # Reduce LR by a factor of 0.5\n",
    "    patience=1,                 # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True,               # Print a message when LR is updated\n",
    "    threshold=0.0001,           # Threshold for measuring the new optimum\n",
    "    threshold_mode='rel',       # Mode for threshold\n",
    "    cooldown=0,                 # Number of epochs to wait before resuming normal operation after LR has been reduced\n",
    "    min_lr=1e-6                 # Lower bound on the learning rate\n",
    ")\n",
    "\n",
    "# scheduler2 = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6cdb04f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:12.500209Z",
     "iopub.status.busy": "2024-11-22T07:59:12.499959Z",
     "iopub.status.idle": "2024-11-22T07:59:43.949649Z",
     "shell.execute_reply": "2024-11-22T07:59:43.948683Z"
    },
    "papermill": {
     "duration": 31.460995,
     "end_time": "2024-11-22T07:59:43.951571",
     "exception": false,
     "start_time": "2024-11-22T07:59:12.490576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtu7pham7\u001b[0m (\u001b[33mhustcollab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.18.7 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.12\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241122_075914-9p2rqccj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mrich-dream-39\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ğŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment/runs/9p2rqccj\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(\n",
    "    # set the wandb project where this run will be logged\n",
    "#     project= \"PolypSegment\", \n",
    "    key = \"e02f7703b40a2b3e0ab4801d4cb1d86b3b7327a6\",\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"PolypSegment\",\n",
    "    config={\n",
    "        \"model\" : \"Unet\",\n",
    "        \"init_learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_functions\": [\"CrossEntropy\", \"Dice\"],\n",
    "        \"imsize\": img_resize\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the model to WandB\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "042cc9d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T07:59:43.984303Z",
     "iopub.status.busy": "2024-11-22T07:59:43.983996Z",
     "iopub.status.idle": "2024-11-22T09:12:38.749794Z",
     "shell.execute_reply": "2024-11-22T09:12:38.748939Z"
    },
    "papermill": {
     "duration": 4374.799667,
     "end_time": "2024-11-22T09:12:38.765912",
     "exception": false,
     "start_time": "2024-11-22T07:59:43.966245",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 0.0582111004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   2%|â–         | 1/50 [01:45<1:25:49, 105.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/50], Loss: 0.0452912205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   4%|â–         | 2/50 [03:12<1:15:48, 94.77s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/50], Loss: 0.0322426997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   6%|â–Œ         | 3/50 [04:39<1:11:18, 91.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/50], Loss: 0.0309101378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   8%|â–Š         | 4/50 [06:07<1:08:56, 89.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/50], Loss: 0.0307039962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|â–ˆ         | 5/50 [07:33<1:06:30, 88.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/50], Loss: 0.0279898258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  12%|â–ˆâ–        | 6/50 [09:00<1:04:37, 88.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/50], Loss: 0.0247597756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  14%|â–ˆâ–        | 7/50 [10:28<1:03:01, 87.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/50], Loss: 0.0242401455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  18%|â–ˆâ–Š        | 9/50 [13:22<59:39, 87.30s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/50], Loss: 0.0284617179\n",
      "Epoch [10/50], Loss: 0.0242198652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|â–ˆâ–ˆ        | 10/50 [14:54<59:16, 88.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/50], Loss: 0.0226467089\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  22%|â–ˆâ–ˆâ–       | 11/50 [16:23<57:40, 88.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/50], Loss: 0.0190833160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  26%|â–ˆâ–ˆâ–Œ       | 13/50 [19:18<54:19, 88.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/50], Loss: 0.0260064495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  28%|â–ˆâ–ˆâ–Š       | 14/50 [20:45<52:39, 87.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/50], Loss: 0.0247940687\n",
      "Epoch 00014: reducing learning rate of group 0 to 5.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|â–ˆâ–ˆâ–ˆ       | 15/50 [22:12<51:06, 87.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/50], Loss: 0.0240726617\n",
      "Epoch [16/50], Loss: 0.0187539236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  34%|â–ˆâ–ˆâ–ˆâ–      | 17/50 [25:07<48:07, 87.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/50], Loss: 0.0208930546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 18/50 [26:34<46:34, 87.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/50], Loss: 0.0211521225\n",
      "Epoch 00018: reducing learning rate of group 0 to 2.5000e-04.\n",
      "Epoch [19/50], Loss: 0.0175430582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 20/50 [29:29<43:44, 87.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/50], Loss: 0.0188003019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 21/50 [30:56<42:12, 87.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/50], Loss: 0.0182789911\n",
      "Epoch 00021: reducing learning rate of group 0 to 1.2500e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 22/50 [32:23<40:42, 87.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/50], Loss: 0.0181788382\n",
      "Epoch [23/50], Loss: 0.0169689293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 23/50 [33:51<39:17, 87.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/50], Loss: 0.0166328383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 25/50 [36:47<36:32, 87.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/50], Loss: 0.0191776928\n",
      "Epoch [26/50], Loss: 0.0165646054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 27/50 [39:41<33:29, 87.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/50], Loss: 0.0167834026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 28/50 [41:08<31:58, 87.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/50], Loss: 0.0167707717\n",
      "Epoch 00028: reducing learning rate of group 0 to 6.2500e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 29/50 [42:36<30:34, 87.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/50], Loss: 0.0169895097\n",
      "Epoch [30/50], Loss: 0.0165445895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 30/50 [44:03<29:08, 87.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/50], Loss: 0.0160437256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 32/50 [46:57<26:07, 87.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/50], Loss: 0.0170072748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 33/50 [48:23<24:38, 86.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/50], Loss: 0.0178783741\n",
      "Epoch 00033: reducing learning rate of group 0 to 3.1250e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 34/50 [49:50<23:10, 86.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/50], Loss: 0.0195238769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 35/50 [51:16<21:41, 86.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/50], Loss: 0.0168414776\n",
      "Epoch 00035: reducing learning rate of group 0 to 1.5625e-05.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 36/50 [52:43<20:14, 86.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/50], Loss: 0.0165423445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 37/50 [54:10<18:46, 86.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/50], Loss: 0.0167215159\n",
      "Epoch 00037: reducing learning rate of group 0 to 7.8125e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 38/50 [55:36<17:19, 86.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Loss: 0.0187112865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 39/50 [57:03<15:52, 86.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/50], Loss: 0.0223386262\n",
      "Epoch 00039: reducing learning rate of group 0 to 3.9063e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 40/50 [58:29<14:24, 86.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/50], Loss: 0.0163160229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 41/50 [59:55<12:57, 86.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/50], Loss: 0.0177061336\n",
      "Epoch 00041: reducing learning rate of group 0 to 1.9531e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 42/50 [1:01:21<11:30, 86.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/50], Loss: 0.0173138840\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 43/50 [1:02:47<10:02, 86.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/50], Loss: 0.0165219170\n",
      "Epoch 00043: reducing learning rate of group 0 to 1.0000e-06.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 44/50 [1:04:13<08:36, 86.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/50], Loss: 0.0172986308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 45/50 [1:05:38<07:09, 85.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/50], Loss: 0.0186241843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 46/50 [1:07:06<05:45, 86.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/50], Loss: 0.0163012522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 47/50 [1:08:33<04:20, 86.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/50], Loss: 0.0163860522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 48/50 [1:10:01<02:54, 87.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/50], Loss: 0.0164593038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 49/50 [1:11:28<01:26, 86.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/50], Loss: 0.0167659952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [1:12:54<00:00, 87.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/50], Loss: 0.0166224075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        outputs = model(images)\n",
    "    \n",
    "        loss_ce = criterion_ce(outputs, labels)\n",
    "        loss_dice = criterion_dice(outputs, labels)\n",
    "        loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "#         del images, labels, outputs, loss\n",
    "#         torch.cuda.empty_cache()\n",
    "        \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_loss = 0\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            outputs = model(images)\n",
    "\n",
    "            val_loss += criterion_dice(outputs.float(),labels.long()).item()\n",
    "            \n",
    "#             del images, labels, outputs\n",
    "#             torch.cuda.empty_cache()\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    epoch_bar.update(1)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader), 'Learning_rate' : current_lr})\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2e7ae6eb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:12:38.801175Z",
     "iopub.status.busy": "2024-11-22T09:12:38.800850Z",
     "iopub.status.idle": "2024-11-22T09:12:39.071326Z",
     "shell.execute_reply": "2024-11-22T09:12:39.070540Z"
    },
    "papermill": {
     "duration": 0.293697,
     "end_time": "2024-11-22T09:12:39.073343",
     "exception": false,
     "start_time": "2024-11-22T09:12:38.779646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (encoder): ResNetEncoder(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder): UnetDecoder(\n",
       "    (center): Identity()\n",
       "    (blocks): ModuleList(\n",
       "      (0): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (1): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (2): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (3): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "      (4): DecoderBlock(\n",
       "        (conv1): Conv2dReLU(\n",
       "          (0): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention1): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "        (conv2): Conv2dReLU(\n",
       "          (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (attention2): Attention(\n",
       "          (attention): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (segmentation_head): SegmentationHead(\n",
       "    (0): Conv2d(16, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): Identity()\n",
       "    (2): Activation(\n",
       "      (activation): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = smp.UnetPlusPlus(\n",
    "#     encoder_name=\"resnet34\",        \n",
    "#     encoder_weights=\"imagenet\",     \n",
    "#     in_channels=3,                  \n",
    "#     classes=3     \n",
    "# )\n",
    "checkpoint = torch.load('/kaggle/working/model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9523177e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:12:39.155300Z",
     "iopub.status.busy": "2024-11-22T09:12:39.154655Z",
     "iopub.status.idle": "2024-11-22T09:12:40.184346Z",
     "shell.execute_reply": "2024-11-22T09:12:40.183117Z"
    },
    "papermill": {
     "duration": 1.04678,
     "end_time": "2024-11-22T09:12:40.186542",
     "exception": false,
     "start_time": "2024-11-22T09:12:39.139762",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37e6c70",
   "metadata": {
    "papermill": {
     "duration": 0.013495,
     "end_time": "2024-11-22T09:12:40.214453",
     "exception": false,
     "start_time": "2024-11-22T09:12:40.200958",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Testset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdec2627",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:12:40.243983Z",
     "iopub.status.busy": "2024-11-22T09:12:40.243602Z",
     "iopub.status.idle": "2024-11-22T09:13:08.773356Z",
     "shell.execute_reply": "2024-11-22T09:13:08.772469Z"
    },
    "papermill": {
     "duration": 28.547731,
     "end_time": "2024-11-22T09:13:08.775910",
     "exception": false,
     "start_time": "2024-11-22T09:12:40.228179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n",
    "    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n",
    "    ori_img = cv2.imread(img_path)\n",
    "    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n",
    "    ori_h = ori_img.shape[0]\n",
    "    ori_w = ori_img.shape[1]\n",
    "    img = cv2.resize(ori_img, img_resize, interpolation=cv2.INTER_AREA)\n",
    "    transformed = val_transformation(image=img)\n",
    "    input_img = transformed[\"image\"]\n",
    "    input_img = input_img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output_mask = model(input_img).squeeze(0).cpu().numpy().transpose(1, 2, 0)\n",
    "    mask = cv2.resize(output_mask, (ori_w, ori_h), interpolation=cv2.INTER_CUBIC)\n",
    "    mask = np.argmax(mask, axis=2)\n",
    "    mask_rgb = mask_to_rgb(mask, color_dict)\n",
    "    mask_rgb = cv2.cvtColor(mask_rgb, cv2.COLOR_RGB2BGR)\n",
    "    cv2.imwrite(\"prediction/{}\".format(i), mask_rgb)\n",
    "    # Clear variables to free memory\n",
    "    del img, input_img, output_mask, mask, mask_rgb\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f59b11",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:13:08.816861Z",
     "iopub.status.busy": "2024-11-22T09:13:08.816530Z",
     "iopub.status.idle": "2024-11-22T09:13:11.607340Z",
     "shell.execute_reply": "2024-11-22T09:13:11.606604Z"
    },
    "papermill": {
     "duration": 2.808302,
     "end_time": "2024-11-22T09:13:11.609364",
     "exception": false,
     "start_time": "2024-11-22T09:13:08.801062",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        # print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75654c19",
   "metadata": {
    "papermill": {
     "duration": 0.013683,
     "end_time": "2024-11-22T09:13:11.637624",
     "exception": false,
     "start_time": "2024-11-22T09:13:11.623941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8575354c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:13:11.666739Z",
     "iopub.status.busy": "2024-11-22T09:13:11.666423Z",
     "iopub.status.idle": "2024-11-22T09:13:11.669929Z",
     "shell.execute_reply": "2024-11-22T09:13:11.669184Z"
    },
    "papermill": {
     "duration": 0.020152,
     "end_time": "2024-11-22T09:13:11.671627",
     "exception": false,
     "start_time": "2024-11-22T09:13:11.651475",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from torch.jit import load\n",
    "# model = UNet()\n",
    "# optimizer = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "\n",
    "# checkpoint = torch.load(pretrained_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a7c9df3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:13:11.701748Z",
     "iopub.status.busy": "2024-11-22T09:13:11.701013Z",
     "iopub.status.idle": "2024-11-22T09:13:11.704836Z",
     "shell.execute_reply": "2024-11-22T09:13:11.704076Z"
    },
    "papermill": {
     "duration": 0.020212,
     "end_time": "2024-11-22T09:13:11.706337",
     "exception": false,
     "start_time": "2024-11-22T09:13:11.686125",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# optimizer.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61f58315",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-22T09:13:11.735442Z",
     "iopub.status.busy": "2024-11-22T09:13:11.735000Z",
     "iopub.status.idle": "2024-11-22T09:13:11.738491Z",
     "shell.execute_reply": "2024-11-22T09:13:11.737738Z"
    },
    "papermill": {
     "duration": 0.019888,
     "end_time": "2024-11-22T09:13:11.740068",
     "exception": false,
     "start_time": "2024-11-22T09:13:11.720180",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from collections import OrderedDict\n",
    "# new_state_dict = OrderedDict()\n",
    "# for k, v in checkpoint['model'].items():\n",
    "#     name = k[7:] # remove `module.`\n",
    "#     new_state_dict[name] = v\n",
    "# # load params\n",
    "# model.load_state_dict(new_state_dict)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "sourceId": 208797485,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30580,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 4494.775626,
   "end_time": "2024-11-22T09:13:14.476654",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-22T07:58:19.701028",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
