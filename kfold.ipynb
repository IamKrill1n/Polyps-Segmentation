{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc668c2a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:31.016481Z",
     "iopub.status.busy": "2024-11-24T09:26:31.016207Z",
     "iopub.status.idle": "2024-11-24T09:26:45.348608Z",
     "shell.execute_reply": "2024-11-24T09:26:45.347464Z"
    },
    "papermill": {
     "duration": 14.339369,
     "end_time": "2024-11-24T09:26:45.350658",
     "exception": false,
     "start_time": "2024-11-24T09:26:31.011289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a769e2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:45.359682Z",
     "iopub.status.busy": "2024-11-24T09:26:45.358995Z",
     "iopub.status.idle": "2024-11-24T09:26:55.187837Z",
     "shell.execute_reply": "2024-11-24T09:26:55.187153Z"
    },
    "papermill": {
     "duration": 9.835391,
     "end_time": "2024-11-24T09:26:55.189857",
     "exception": false,
     "start_time": "2024-11-24T09:26:45.354466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "import random\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision \n",
    "from torchvision import transforms\n",
    "# from torchinfo import summary\n",
    "import timm\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5732c48",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:55.198129Z",
     "iopub.status.busy": "2024-11-24T09:26:55.197847Z",
     "iopub.status.idle": "2024-11-24T09:26:56.416923Z",
     "shell.execute_reply": "2024-11-24T09:26:56.416043Z"
    },
    "papermill": {
     "duration": 1.224969,
     "end_time": "2024-11-24T09:26:56.418598",
     "exception": false,
     "start_time": "2024-11-24T09:26:55.193629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65328443",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:56.428354Z",
     "iopub.status.busy": "2024-11-24T09:26:56.427691Z",
     "iopub.status.idle": "2024-11-24T09:26:57.544622Z",
     "shell.execute_reply": "2024-11-24T09:26:57.543715Z"
    },
    "papermill": {
     "duration": 1.124429,
     "end_time": "2024-11-24T09:26:57.546646",
     "exception": false,
     "start_time": "2024-11-24T09:26:56.422217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52796a97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:57.555994Z",
     "iopub.status.busy": "2024-11-24T09:26:57.555728Z",
     "iopub.status.idle": "2024-11-24T09:26:57.568148Z",
     "shell.execute_reply": "2024-11-24T09:26:57.567416Z"
    },
    "papermill": {
     "duration": 0.01884,
     "end_time": "2024-11-24T09:26:57.569790",
     "exception": false,
     "start_time": "2024-11-24T09:26:57.550950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir=\"path/to/data\", resize = None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.resize = resize\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width, channels = image.shape\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        name =  os.path.basename(img_path)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image, height, width, name[:-5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8597e9cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:57.578180Z",
     "iopub.status.busy": "2024-11-24T09:26:57.577656Z",
     "iopub.status.idle": "2024-11-24T09:26:57.582767Z",
     "shell.execute_reply": "2024-11-24T09:26:57.582140Z"
    },
    "papermill": {
     "duration": 0.010836,
     "end_time": "2024-11-24T09:26:57.584189",
     "exception": false,
     "start_time": "2024-11-24T09:26:57.573353",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AugmentDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, length_multiplier=1):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.length_multiplier = length_multiplier\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx % len(self.dataset)\n",
    "        image, label = self.dataset[actual_idx]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * self.length_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6ad3c98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:57.592176Z",
     "iopub.status.busy": "2024-11-24T09:26:57.591897Z",
     "iopub.status.idle": "2024-11-24T09:26:57.598951Z",
     "shell.execute_reply": "2024-11-24T09:26:57.598273Z"
    },
    "papermill": {
     "duration": 0.012785,
     "end_time": "2024-11-24T09:26:57.600396",
     "exception": false,
     "start_time": "2024-11-24T09:26:57.587611",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    # A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "    # A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "    \n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f983ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:57.608835Z",
     "iopub.status.busy": "2024-11-24T09:26:57.607997Z",
     "iopub.status.idle": "2024-11-24T09:26:57.612221Z",
     "shell.execute_reply": "2024-11-24T09:26:57.611502Z"
    },
    "papermill": {
     "duration": 0.010006,
     "end_time": "2024-11-24T09:26:57.613836",
     "exception": false,
     "start_time": "2024-11-24T09:26:57.603830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = (256, 256)\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "alpha = 0.5  # Weight of cross entropy loss \n",
    "num_epochs = 20\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b7bc4e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:26:57.622005Z",
     "iopub.status.busy": "2024-11-24T09:26:57.621763Z",
     "iopub.status.idle": "2024-11-24T09:54:23.357174Z",
     "shell.execute_reply": "2024-11-24T09:54:23.356140Z"
    },
    "papermill": {
     "duration": 1645.741722,
     "end_time": "2024-11-24T09:54:23.359072",
     "exception": false,
     "start_time": "2024-11-24T09:26:57.617350",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet34-333f7ec4.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-333f7ec4.pth\n",
      "100%|██████████| 83.3M/83.3M [00:01<00:00, 87.1MB/s]\n",
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training Loss: 0.7331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▌         | 1/20 [00:18<05:58, 18.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6396\n",
      "\n",
      "Epoch 2/20\n",
      "Training Loss: 0.3627\n",
      "Validation Loss: 0.4999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 2/20 [00:35<05:15, 17.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Training Loss: 0.2661\n",
      "Validation Loss: 0.3926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|█▌        | 3/20 [00:51<04:48, 16.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Training Loss: 0.2268\n",
      "Validation Loss: 0.3436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 4/20 [01:08<04:29, 16.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n",
      "Training Loss: 0.2093\n",
      "Validation Loss: 0.3034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|██▌       | 5/20 [01:24<04:09, 16.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "Training Loss: 0.2105\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 6/20 [01:41<03:52, 16.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3302\n",
      "\n",
      "Epoch 7/20\n",
      "Training Loss: 0.1956\n",
      "Validation Loss: 0.2770\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|███▌      | 7/20 [01:57<03:35, 16.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Training Loss: 0.1753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 8/20 [02:14<03:18, 16.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3145\n",
      "\n",
      "Epoch 9/20\n",
      "Training Loss: 0.1804\n",
      "Validation Loss: 0.2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|████▌     | 9/20 [02:30<03:01, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Training Loss: 0.1627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 10/20 [02:47<02:44, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2677\n",
      "\n",
      "Epoch 11/20\n",
      "Training Loss: 0.1502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|█████▌    | 11/20 [03:03<02:27, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2499\n",
      "\n",
      "Epoch 12/20\n",
      "Training Loss: 0.1385\n",
      "Validation Loss: 0.2103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 12/20 [03:20<02:11, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Training Loss: 0.1196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|██████▌   | 13/20 [03:35<01:54, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2141\n",
      "\n",
      "Epoch 14/20\n",
      "Training Loss: 0.1151\n",
      "Validation Loss: 0.1904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 14/20 [03:52<01:38, 16.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Training Loss: 0.1157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|███████▌  | 15/20 [04:08<01:21, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1928\n",
      "\n",
      "Epoch 16/20\n",
      "Training Loss: 0.1090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 16/20 [04:24<01:05, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2081\n",
      "\n",
      "Epoch 17/20\n",
      "Training Loss: 0.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 17/20 [04:41<00:48, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2101\n",
      "\n",
      "Epoch 18/20\n",
      "Training Loss: 0.1010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 18/20 [04:57<00:32, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2097\n",
      "\n",
      "Epoch 19/20\n",
      "Training Loss: 0.0995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  95%|█████████▌| 19/20 [05:13<00:16, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2113\n",
      "\n",
      "Epoch 20/20\n",
      "Training Loss: 0.0988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 20/20 [05:29<00:00, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2102\n",
      "Model saved to model_fold_1.pth\n",
      "\n",
      "Fold 2/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training Loss: 0.5321\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▌         | 1/20 [00:16<05:18, 16.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5426\n",
      "\n",
      "Epoch 2/20\n",
      "Training Loss: 0.2828\n",
      "Validation Loss: 0.4932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 2/20 [00:33<04:58, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Training Loss: 0.2482\n",
      "Validation Loss: 0.3989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|█▌        | 3/20 [00:49<04:40, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Training Loss: 0.2281\n",
      "Validation Loss: 0.3725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 4/20 [01:05<04:23, 16.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/20\n",
      "Training Loss: 0.2337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|██▌       | 5/20 [01:22<04:04, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4385\n",
      "\n",
      "Epoch 6/20\n",
      "Training Loss: 0.2215\n",
      "Validation Loss: 0.3709\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 6/20 [01:38<03:49, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n",
      "Training Loss: 0.2116\n",
      "Validation Loss: 0.3627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|███▌      | 7/20 [01:54<03:33, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Training Loss: 0.2119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 8/20 [02:11<03:15, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4107\n",
      "\n",
      "Epoch 9/20\n",
      "Training Loss: 0.2059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|████▌     | 9/20 [02:27<02:59, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3637\n",
      "\n",
      "Epoch 10/20\n",
      "Training Loss: 0.1791\n",
      "Validation Loss: 0.2969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 10/20 [02:43<02:43, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n",
      "Training Loss: 0.1636\n",
      "Validation Loss: 0.2776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|█████▌    | 11/20 [03:00<02:27, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "Training Loss: 0.1525\n",
      "Validation Loss: 0.2552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 12/20 [03:16<02:10, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Training Loss: 0.1424\n",
      "Validation Loss: 0.2379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|██████▌   | 13/20 [03:33<01:54, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "Training Loss: 0.1349\n",
      "Validation Loss: 0.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 14/20 [03:49<01:38, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Training Loss: 0.1249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|███████▌  | 15/20 [04:05<01:21, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2356\n",
      "\n",
      "Epoch 16/20\n",
      "Training Loss: 0.1145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 16/20 [04:21<01:04, 16.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2399\n",
      "\n",
      "Epoch 17/20\n",
      "Training Loss: 0.1106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 17/20 [04:37<00:48, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2368\n",
      "\n",
      "Epoch 18/20\n",
      "Training Loss: 0.1102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 18/20 [04:53<00:32, 16.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2332\n",
      "\n",
      "Epoch 19/20\n",
      "Training Loss: 0.1110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  95%|█████████▌| 19/20 [05:09<00:16, 16.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2325\n",
      "\n",
      "Epoch 20/20\n",
      "Training Loss: 0.1113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 20/20 [05:25<00:00, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2343\n",
      "Model saved to model_fold_2.pth\n",
      "\n",
      "Fold 3/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training Loss: 0.5432\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▌         | 1/20 [00:16<05:09, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5579\n",
      "\n",
      "Epoch 2/20\n",
      "Training Loss: 0.2823\n",
      "Validation Loss: 0.5146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 2/20 [00:32<04:54, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Training Loss: 0.2438\n",
      "Validation Loss: 0.4102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|█▌        | 3/20 [00:49<04:38, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Training Loss: 0.2383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 4/20 [01:05<04:20, 16.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4206\n",
      "\n",
      "Epoch 5/20\n",
      "Training Loss: 0.2081\n",
      "Validation Loss: 0.3779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|██▌       | 5/20 [01:21<04:05, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "Training Loss: 0.2002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 6/20 [01:37<03:47, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4664\n",
      "\n",
      "Epoch 7/20\n",
      "Training Loss: 0.2003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|███▌      | 7/20 [01:54<03:33, 16.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3928\n",
      "\n",
      "Epoch 8/20\n",
      "Training Loss: 0.1761\n",
      "Validation Loss: 0.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 8/20 [02:11<03:17, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n",
      "Training Loss: 0.1570\n",
      "Validation Loss: 0.2762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|████▌     | 9/20 [02:28<03:04, 16.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Training Loss: 0.1474\n",
      "Validation Loss: 0.2638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 10/20 [02:45<02:48, 16.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 11/20\n",
      "Training Loss: 0.1356\n",
      "Validation Loss: 0.2577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|█████▌    | 11/20 [03:02<02:32, 16.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "Training Loss: 0.1342\n",
      "Validation Loss: 0.2548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 12/20 [03:19<02:15, 16.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Training Loss: 0.1248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|██████▌   | 13/20 [03:36<01:58, 16.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2581\n",
      "\n",
      "Epoch 14/20\n",
      "Training Loss: 0.1197\n",
      "Validation Loss: 0.2497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 14/20 [03:52<01:40, 16.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Training Loss: 0.1157\n",
      "Validation Loss: 0.2452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|███████▌  | 15/20 [04:09<01:23, 16.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "Training Loss: 0.1138\n",
      "Validation Loss: 0.2365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 16/20 [04:25<01:06, 16.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n",
      "Training Loss: 0.1099\n",
      "Validation Loss: 0.2332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 17/20 [04:42<00:49, 16.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20\n",
      "Training Loss: 0.1002\n",
      "Validation Loss: 0.2330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 18/20 [04:58<00:33, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 19/20\n",
      "Training Loss: 0.0998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  95%|█████████▌| 19/20 [05:15<00:16, 16.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2380\n",
      "\n",
      "Epoch 20/20\n",
      "Training Loss: 0.0979\n",
      "Validation Loss: 0.2313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 20/20 [05:31<00:00, 16.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to model_fold_3.pth\n",
      "\n",
      "Fold 4/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training Loss: 0.5095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▌         | 1/20 [00:16<05:16, 16.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5901\n",
      "\n",
      "Epoch 2/20\n",
      "Training Loss: 0.2863\n",
      "Validation Loss: 0.4263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 2/20 [00:33<04:57, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Training Loss: 0.2432\n",
      "Validation Loss: 0.4057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|█▌        | 3/20 [00:49<04:40, 16.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Training Loss: 0.2126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 4/20 [01:05<04:22, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4509\n",
      "\n",
      "Epoch 5/20\n",
      "Training Loss: 0.2108\n",
      "Validation Loss: 0.3307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|██▌       | 5/20 [01:22<04:05, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/20\n",
      "Training Loss: 0.1875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 6/20 [01:38<03:49, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3672\n",
      "\n",
      "Epoch 7/20\n",
      "Training Loss: 0.1702\n",
      "Validation Loss: 0.2897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|███▌      | 7/20 [01:54<03:32, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Training Loss: 0.1531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 8/20 [02:11<03:17, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3277\n",
      "\n",
      "Epoch 9/20\n",
      "Training Loss: 0.1631\n",
      "Validation Loss: 0.2665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|████▌     | 9/20 [02:27<03:00, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Training Loss: 0.1563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 10/20 [02:44<02:44, 16.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3561\n",
      "\n",
      "Epoch 11/20\n",
      "Training Loss: 0.1452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|█████▌    | 11/20 [03:00<02:26, 16.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3218\n",
      "\n",
      "Epoch 12/20\n",
      "Training Loss: 0.1329\n",
      "Validation Loss: 0.2556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 12/20 [03:16<02:11, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 13/20\n",
      "Training Loss: 0.1148\n",
      "Validation Loss: 0.2476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|██████▌   | 13/20 [03:33<01:54, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "Training Loss: 0.1073\n",
      "Validation Loss: 0.2416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 14/20 [03:49<01:38, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Training Loss: 0.1147\n",
      "Validation Loss: 0.2406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|███████▌  | 15/20 [04:05<01:21, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "Training Loss: 0.1032\n",
      "Validation Loss: 0.2296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 16/20 [04:22<01:05, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 17/20\n",
      "Training Loss: 0.0969\n",
      "Validation Loss: 0.2173\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 17/20 [04:38<00:49, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 18/20\n",
      "Training Loss: 0.0923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 18/20 [04:54<00:32, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2201\n",
      "\n",
      "Epoch 19/20\n",
      "Training Loss: 0.0802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  95%|█████████▌| 19/20 [05:10<00:16, 16.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2173\n",
      "\n",
      "Epoch 20/20\n",
      "Training Loss: 0.0919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 20/20 [05:27<00:00, 16.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2177\n",
      "Model saved to model_fold_4.pth\n",
      "\n",
      "Fold 5/5\n",
      "--------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/20\n",
      "Training Loss: 0.4086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|▌         | 1/20 [00:16<05:10, 16.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.6150\n",
      "\n",
      "Epoch 2/20\n",
      "Training Loss: 0.2550\n",
      "Validation Loss: 0.4289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|█         | 2/20 [00:32<04:57, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3/20\n",
      "Training Loss: 0.2316\n",
      "Validation Loss: 0.3758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|█▌        | 3/20 [00:49<04:40, 16.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4/20\n",
      "Training Loss: 0.2120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|██        | 4/20 [01:05<04:24, 16.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.5374\n",
      "\n",
      "Epoch 5/20\n",
      "Training Loss: 0.2229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|██▌       | 5/20 [01:22<04:05, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.4113\n",
      "\n",
      "Epoch 6/20\n",
      "Training Loss: 0.1986\n",
      "Validation Loss: 0.3167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|███       | 6/20 [01:38<03:48, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7/20\n",
      "Training Loss: 0.1751\n",
      "Validation Loss: 0.2920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|███▌      | 7/20 [01:54<03:32, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8/20\n",
      "Training Loss: 0.1571\n",
      "Validation Loss: 0.2918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|████      | 8/20 [02:11<03:17, 16.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9/20\n",
      "Training Loss: 0.1527\n",
      "Validation Loss: 0.2703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|████▌     | 9/20 [02:27<03:00, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/20\n",
      "Training Loss: 0.1440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  50%|█████     | 10/20 [02:44<02:43, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2721\n",
      "\n",
      "Epoch 11/20\n",
      "Training Loss: 0.1368\n",
      "Validation Loss: 0.2593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|█████▌    | 11/20 [03:00<02:27, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 12/20\n",
      "Training Loss: 0.1335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|██████    | 12/20 [03:16<02:10, 16.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2609\n",
      "\n",
      "Epoch 13/20\n",
      "Training Loss: 0.1255\n",
      "Validation Loss: 0.2547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|██████▌   | 13/20 [03:32<01:53, 16.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 14/20\n",
      "Training Loss: 0.1268\n",
      "Validation Loss: 0.2482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|███████   | 14/20 [03:49<01:38, 16.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 15/20\n",
      "Training Loss: 0.1226\n",
      "Validation Loss: 0.2395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|███████▌  | 15/20 [04:05<01:21, 16.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 16/20\n",
      "Training Loss: 0.1140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|████████  | 16/20 [04:22<01:05, 16.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2463\n",
      "\n",
      "Epoch 17/20\n",
      "Training Loss: 0.1155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|████████▌ | 17/20 [04:38<00:48, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2499\n",
      "\n",
      "Epoch 18/20\n",
      "Training Loss: 0.1066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|█████████ | 18/20 [04:54<00:32, 16.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2406\n",
      "\n",
      "Epoch 19/20\n",
      "Training Loss: 0.1017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  95%|█████████▌| 19/20 [05:10<00:16, 16.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2418\n",
      "\n",
      "Epoch 20/20\n",
      "Training Loss: 0.0994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|██████████| 20/20 [05:26<00:00, 16.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2398\n",
      "Model saved to model_fold_5.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Set random seed for reproducibility\n",
    "from tqdm import tqdm\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = TrainDataset(\n",
    "    img_dir=TRAIN_DIR,\n",
    "    label_dir=TRAIN_MASK_DIR,\n",
    "    resize=img_resize,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "# K-Fold Cross-Validation\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(dataset)):\n",
    "    print(f'\\nFold {fold + 1}/{n_splits}')\n",
    "    print('--------------------------------')\n",
    "\n",
    "    # Subsets for the current fold\n",
    "    train_subset = Subset(dataset, train_idx)\n",
    "    val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "    # Datasets with transformations\n",
    "    train_dataset = AugmentDataset(train_subset, transform=train_transformation)\n",
    "    val_dataset = AugmentDataset(val_subset, transform=val_transformation)\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    # Initialize model\n",
    "    model = smp.UnetPlusPlus(\n",
    "        encoder_name='resnet34',\n",
    "        encoder_weights='imagenet',\n",
    "        in_channels=3,\n",
    "        classes=3\n",
    "    )\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Loss function\n",
    "    criterion_ce = nn.CrossEntropyLoss()\n",
    "    criterion_dice = smp.losses.DiceLoss(mode='multiclass')\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer, \n",
    "        mode='min',                 # We want to minimize the validation loss\n",
    "        factor=0.1,                 # Reduce LR by a factor of 0.5\n",
    "        patience=1,                 # Number of epochs with no improvement after which LR will be reduced\n",
    "        verbose=True,               # Print a message when LR is updated\n",
    "        threshold=0.0001,           # Threshold for measuring the new optimum\n",
    "        threshold_mode='rel',       # Mode for threshold\n",
    "        cooldown=0,                 # Number of epochs to wait before resuming normal operation after LR has been reduced\n",
    "        min_lr=1e-6                 # Lower bound on the learning rate\n",
    "    )\n",
    "    best_val_loss = 999\n",
    "    # Training loop\n",
    "    epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch + 1}/{num_epochs}')\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_dice = criterion_dice(outputs, labels)\n",
    "            loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "           \n",
    "            train_loss += loss.item() * images.size(0)\n",
    "\n",
    "        train_epoch_loss = train_loss / len(train_loader.dataset)\n",
    "        print(f'Training Loss: {train_epoch_loss:.4f}')\n",
    "\n",
    "        # Validation loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images = images.to(device)\n",
    "                labels = labels.to(device)\n",
    "                labels = labels.squeeze(dim=1).long()\n",
    "                outputs = model(images)\n",
    "                # loss_ce = criterion_ce(outputs, labels)\n",
    "                loss_dice = criterion_dice(outputs, labels)\n",
    "                # loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "                val_loss += loss_dice.item() * images.size(0)\n",
    "            val_epoch_loss = val_loss / len(val_loader.dataset)\n",
    "            print(f'Validation Loss: {val_epoch_loss:.4f}')\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint = { \n",
    "                'epoch': epoch,\n",
    "                'model': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict(),\n",
    "                'loss': val_loss,\n",
    "            }\n",
    "            model_path = f'model_fold_{fold + 1}.pth'\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "        # Step the scheduler\n",
    "        scheduler.step(val_epoch_loss)\n",
    "        epoch_bar.update(1)\n",
    "    epoch_bar.close()\n",
    "    # Save the model for the current fold\n",
    "    print(f'Model saved to {model_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff0d5ea3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:23.400352Z",
     "iopub.status.busy": "2024-11-24T09:54:23.400024Z",
     "iopub.status.idle": "2024-11-24T09:54:30.602465Z",
     "shell.execute_reply": "2024-11-24T09:54:30.601601Z"
    },
    "papermill": {
     "duration": 7.225138,
     "end_time": "2024-11-24T09:54:30.604194",
     "exception": false,
     "start_time": "2024-11-24T09:54:23.379056",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/2267863117.py:25: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(model_path, map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 models for ensembling.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# List to store models\n",
    "models = []\n",
    "\n",
    "# Number of folds\n",
    "n_splits = 5  # Adjust based on your cross-validation\n",
    "\n",
    "# Model parameters (should match those used during training)\n",
    "model_params = {\n",
    "    'encoder_name': 'resnet34',        # Same encoder as in training\n",
    "    'encoder_weights': None,           # No pretraining since weights are loaded\n",
    "    'in_channels': 3,\n",
    "    'classes': 3                       # Number of segmentation classes\n",
    "}\n",
    "\n",
    "# Load models from each fold\n",
    "for fold in range(n_splits):\n",
    "    model = smp.UnetPlusPlus(**model_params)\n",
    "    model_path = f'/kaggle/input/unetplusplus-resnet34/model_fold_{fold + 1}.pth'\n",
    "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "    model.to(device)\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    models.append(model)\n",
    "\n",
    "print(f'Loaded {len(models)} models for ensembling.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46993640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:30.644821Z",
     "iopub.status.busy": "2024-11-24T09:54:30.644183Z",
     "iopub.status.idle": "2024-11-24T09:54:30.684720Z",
     "shell.execute_reply": "2024-11-24T09:54:30.684139Z"
    },
    "papermill": {
     "duration": 0.062084,
     "end_time": "2024-11-24T09:54:30.686141",
     "exception": false,
     "start_time": "2024-11-24T09:54:30.624057",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(img_dir=\"/kaggle/input/bkai-igh-neopolyp/test/test\", resize=img_resize, transform=val_transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88431c5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:30.727390Z",
     "iopub.status.busy": "2024-11-24T09:54:30.726772Z",
     "iopub.status.idle": "2024-11-24T09:54:30.730612Z",
     "shell.execute_reply": "2024-11-24T09:54:30.729958Z"
    },
    "papermill": {
     "duration": 0.026027,
     "end_time": "2024-11-24T09:54:30.732043",
     "exception": false,
     "start_time": "2024-11-24T09:54:30.706016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2eea6ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:30.773481Z",
     "iopub.status.busy": "2024-11-24T09:54:30.773007Z",
     "iopub.status.idle": "2024-11-24T09:54:30.777624Z",
     "shell.execute_reply": "2024-11-24T09:54:30.776842Z"
    },
    "papermill": {
     "duration": 0.02696,
     "end_time": "2024-11-24T09:54:30.779285",
     "exception": false,
     "start_time": "2024-11-24T09:54:30.752325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "189d4635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:30.819429Z",
     "iopub.status.busy": "2024-11-24T09:54:30.819168Z",
     "iopub.status.idle": "2024-11-24T09:54:30.824227Z",
     "shell.execute_reply": "2024-11-24T09:54:30.823515Z"
    },
    "papermill": {
     "duration": 0.026883,
     "end_time": "2024-11-24T09:54:30.825713",
     "exception": false,
     "start_time": "2024-11-24T09:54:30.798830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Smoothed_img(image):\n",
    "    resized_image = image\n",
    "    smoothed_image = cv2.GaussianBlur(resized_image, (15, 15), 0)\n",
    "    red_pixels = (smoothed_image[:, :, 2] > 100)\n",
    "    green_pixels = (smoothed_image[:, :, 1] > 100)\n",
    "    black_pixels = ~(red_pixels | green_pixels)\n",
    "    smoothed_image[red_pixels] = [0, 0, 255]\n",
    "    smoothed_image[green_pixels] = [0, 255, 0]\n",
    "    smoothed_image[black_pixels] = [0, 0, 0]\n",
    "\n",
    "    pixel_values = np.array(smoothed_image)\n",
    "    # unique_values = np.unique(pixel_values)\n",
    "    # print(unique_values)\n",
    "    return smoothed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0bc0a77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:30.865408Z",
     "iopub.status.busy": "2024-11-24T09:54:30.865180Z",
     "iopub.status.idle": "2024-11-24T09:54:31.892318Z",
     "shell.execute_reply": "2024-11-24T09:54:31.891323Z"
    },
    "papermill": {
     "duration": 1.049187,
     "end_time": "2024-11-24T09:54:31.894401",
     "exception": false,
     "start_time": "2024-11-24T09:54:30.845214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "364ed536",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:31.935647Z",
     "iopub.status.busy": "2024-11-24T09:54:31.934982Z",
     "iopub.status.idle": "2024-11-24T09:54:58.993653Z",
     "shell.execute_reply": "2024-11-24T09:54:58.992689Z"
    },
    "papermill": {
     "duration": 27.081327,
     "end_time": "2024-11-24T09:54:58.995787",
     "exception": false,
     "start_time": "2024-11-24T09:54:31.914460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for image, h, w, name in test_loader:\n",
    "        outputs_list = []\n",
    "        for model in models:\n",
    "            outputs = model(image.to(device))\n",
    "            outputs = outputs.squeeze().cpu().numpy()\n",
    "            outputs_list.append(outputs)\n",
    "        \n",
    "        # Average the class predictions\n",
    "        avg_outputs = np.mean(outputs_list, axis=0)\n",
    "        avg_outputs = np.argmax(avg_outputs, axis=0)\n",
    "        avg_outputs = mask_to_rgb(avg_outputs, color_dict)\n",
    "        \n",
    "        w = w.item()\n",
    "        h = h.item()\n",
    "        new_size = (w, h)\n",
    "        resized_image = cv2.resize(avg_outputs, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Smoothed_img(resized_image)\n",
    "        cv2.imwrite(f\"prediction/{name[0]}.png\", resized_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47cd16ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T09:54:59.036813Z",
     "iopub.status.busy": "2024-11-24T09:54:59.036517Z",
     "iopub.status.idle": "2024-11-24T09:55:02.042874Z",
     "shell.execute_reply": "2024-11-24T09:55:02.042224Z"
    },
    "papermill": {
     "duration": 3.028696,
     "end_time": "2024-11-24T09:55:02.044742",
     "exception": false,
     "start_time": "2024-11-24T09:54:59.016046",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        # print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 6150706,
     "sourceId": 9993523,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1716.523233,
   "end_time": "2024-11-24T09:55:05.097667",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-24T09:26:28.574434",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
