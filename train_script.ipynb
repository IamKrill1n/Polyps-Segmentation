{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45233287",
   "metadata": {
    "papermill": {
     "duration": 0.007875,
     "end_time": "2024-11-24T08:08:50.623079",
     "exception": false,
     "start_time": "2024-11-24T08:08:50.615204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4272d72d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:08:50.639956Z",
     "iopub.status.busy": "2024-11-24T08:08:50.639589Z",
     "iopub.status.idle": "2024-11-24T08:09:05.757276Z",
     "shell.execute_reply": "2024-11-24T08:09:05.756189Z"
    },
    "papermill": {
     "duration": 15.127625,
     "end_time": "2024-11-24T08:09:05.759198",
     "exception": false,
     "start_time": "2024-11-24T08:08:50.631573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip install -q torchsummary\n",
    "# %pip install -q torchgeometry\n",
    "%pip install -q segmentation-models-pytorch\n",
    "# %pip install -q timm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cfc9b8",
   "metadata": {
    "papermill": {
     "duration": 0.006709,
     "end_time": "2024-11-24T08:09:05.773087",
     "exception": false,
     "start_time": "2024-11-24T08:09:05.766378",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "300e7e49",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:05.788903Z",
     "iopub.status.busy": "2024-11-24T08:09:05.788201Z",
     "iopub.status.idle": "2024-11-24T08:09:14.754160Z",
     "shell.execute_reply": "2024-11-24T08:09:14.753138Z"
    },
    "papermill": {
     "duration": 8.976528,
     "end_time": "2024-11-24T08:09:14.756417",
     "exception": false,
     "start_time": "2024-11-24T08:09:05.779889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from torchvision.io import read_image\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, Subset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import os\n",
    "\n",
    "# import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc5fccb5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:14.772892Z",
     "iopub.status.busy": "2024-11-24T08:09:14.772527Z",
     "iopub.status.idle": "2024-11-24T08:09:15.856103Z",
     "shell.execute_reply": "2024-11-24T08:09:15.854946Z"
    },
    "papermill": {
     "duration": 1.094092,
     "end_time": "2024-11-24T08:09:15.858313",
     "exception": false,
     "start_time": "2024-11-24T08:09:14.764221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-5b1fe213-19c6-ef5f-4ad7-8e6b8d35fd00)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37a0562e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:15.874936Z",
     "iopub.status.busy": "2024-11-24T08:09:15.874533Z",
     "iopub.status.idle": "2024-11-24T08:09:15.936471Z",
     "shell.execute_reply": "2024-11-24T08:09:15.935480Z"
    },
    "papermill": {
     "duration": 0.07213,
     "end_time": "2024-11-24T08:09:15.938076",
     "exception": false,
     "start_time": "2024-11-24T08:09:15.865946",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1faec57f",
   "metadata": {
    "papermill": {
     "duration": 0.007109,
     "end_time": "2024-11-24T08:09:15.952549",
     "exception": false,
     "start_time": "2024-11-24T08:09:15.945440",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b25da28e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:15.968893Z",
     "iopub.status.busy": "2024-11-24T08:09:15.967994Z",
     "iopub.status.idle": "2024-11-24T08:09:16.399039Z",
     "shell.execute_reply": "2024-11-24T08:09:16.398095Z"
    },
    "papermill": {
     "duration": 0.441454,
     "end_time": "2024-11-24T08:09:16.401152",
     "exception": false,
     "start_time": "2024-11-24T08:09:15.959698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3122626b",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:16.418661Z",
     "iopub.status.busy": "2024-11-24T08:09:16.418276Z",
     "iopub.status.idle": "2024-11-24T08:09:16.423465Z",
     "shell.execute_reply": "2024-11-24T08:09:16.421910Z"
    },
    "papermill": {
     "duration": 0.015694,
     "end_time": "2024-11-24T08:09:16.425046",
     "exception": false,
     "start_time": "2024-11-24T08:09:16.409352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def calculate_mean_image_size(image_dir):\n",
    "#     widths = []\n",
    "#     heights = []\n",
    "\n",
    "#     for filename in os.listdir(image_dir):\n",
    "#         if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "#             img_path = os.path.join(image_dir, filename)\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 h, w = image.shape[:2]\n",
    "#                 heights.append(h)\n",
    "#                 widths.append(w)\n",
    "#             else:\n",
    "#                 print(f\"Warning: Unable to read image {img_path}\")\n",
    "\n",
    "#     mean_width = int(np.mean(widths))\n",
    "#     mean_height = int(np.mean(heights))\n",
    "#     median_width = int(np.median(widths))\n",
    "#     median_height = int(np.median(heights))\n",
    "\n",
    "#     print(f\"Number of images: {len(widths)}\")\n",
    "#     print(f\"Mean Width: {mean_width}, Mean Height: {mean_height}\")\n",
    "#     print(f\"Median Width: {median_width}, Median Height: {median_height}\")\n",
    "\n",
    "#     return mean_width, mean_height, widths, heights\n",
    "\n",
    "# # Example usage:\n",
    "# image_directory = '/kaggle/input/bkai-igh-neopolyp/test/test'\n",
    "# mean_w, mean_h, widths, heights = calculate_mean_image_size(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a52e7aea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:16.442236Z",
     "iopub.status.busy": "2024-11-24T08:09:16.441440Z",
     "iopub.status.idle": "2024-11-24T08:09:16.445666Z",
     "shell.execute_reply": "2024-11-24T08:09:16.444805Z"
    },
    "papermill": {
     "duration": 0.014341,
     "end_time": "2024-11-24T08:09:16.447381",
     "exception": false,
     "start_time": "2024-11-24T08:09:16.433040",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_dimension_distribution(widths, heights):\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.hist(widths, bins=20, color='skyblue')\n",
    "#     plt.title('Width Distribution')\n",
    "#     plt.xlabel('Width')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.hist(heights, bins=20, color='salmon')\n",
    "#     plt.title('Height Distribution')\n",
    "#     plt.xlabel('Height')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # After collecting widths and heights in the function above:\n",
    "# plot_dimension_distribution(widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83eadd5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:16.463907Z",
     "iopub.status.busy": "2024-11-24T08:09:16.463126Z",
     "iopub.status.idle": "2024-11-24T08:09:17.088036Z",
     "shell.execute_reply": "2024-11-24T08:09:17.087111Z"
    },
    "papermill": {
     "duration": 0.635158,
     "end_time": "2024-11-24T08:09:17.089845",
     "exception": false,
     "start_time": "2024-11-24T08:09:16.454687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4165b79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.106275Z",
     "iopub.status.busy": "2024-11-24T08:09:17.105981Z",
     "iopub.status.idle": "2024-11-24T08:09:17.117999Z",
     "shell.execute_reply": "2024-11-24T08:09:17.117075Z"
    },
    "papermill": {
     "duration": 0.022487,
     "end_time": "2024-11-24T08:09:17.119700",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.097213",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir=\"path/to/data\", resize = None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.resize = resize\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width, channels = image.shape\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        name =  os.path.basename(img_path)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image, height, width, name[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71021d29",
   "metadata": {
    "papermill": {
     "duration": 0.007111,
     "end_time": "2024-11-24T08:09:17.134337",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.127226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2b31d146",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.150733Z",
     "iopub.status.busy": "2024-11-24T08:09:17.150047Z",
     "iopub.status.idle": "2024-11-24T08:09:17.154112Z",
     "shell.execute_reply": "2024-11-24T08:09:17.153394Z"
    },
    "papermill": {
     "duration": 0.014079,
     "end_time": "2024-11-24T08:09:17.155772",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.141693",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = (256, 256)\n",
    "batch_size = 32\n",
    "learning_rate = 1e-3\n",
    "alpha = 0.5  # Weight of cross entropy loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7a4e2e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.170858Z",
     "iopub.status.busy": "2024-11-24T08:09:17.170576Z",
     "iopub.status.idle": "2024-11-24T08:09:17.174845Z",
     "shell.execute_reply": "2024-11-24T08:09:17.174022Z"
    },
    "papermill": {
     "duration": 0.013579,
     "end_time": "2024-11-24T08:09:17.176455",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.162876",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TrainDataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= img_resize,\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043557d7",
   "metadata": {
    "papermill": {
     "duration": 0.007137,
     "end_time": "2024-11-24T08:09:17.190931",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.183794",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27a1b1fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.207975Z",
     "iopub.status.busy": "2024-11-24T08:09:17.207599Z",
     "iopub.status.idle": "2024-11-24T08:09:17.213627Z",
     "shell.execute_reply": "2024-11-24T08:09:17.212811Z"
    },
    "papermill": {
     "duration": 0.017018,
     "end_time": "2024-11-24T08:09:17.215179",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.198161",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AugmentDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, length_multiplier=1):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.length_multiplier = length_multiplier\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx % len(self.dataset)\n",
    "        image, label = self.dataset[actual_idx]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * self.length_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79bc18c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.231750Z",
     "iopub.status.busy": "2024-11-24T08:09:17.231171Z",
     "iopub.status.idle": "2024-11-24T08:09:17.237966Z",
     "shell.execute_reply": "2024-11-24T08:09:17.237036Z"
    },
    "papermill": {
     "duration": 0.017298,
     "end_time": "2024-11-24T08:09:17.239873",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.222575",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * 4  # Four copies per image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx // 4\n",
    "        flip_idx = idx % 4\n",
    "\n",
    "        image, label = self.dataset[actual_idx]\n",
    "\n",
    "        # Apply flips based on flip_idx\n",
    "        if flip_idx == 1:\n",
    "            image = cv2.flip(image, 1)  # Horizontal flip\n",
    "            label = cv2.flip(label, 1)\n",
    "        elif flip_idx == 2:\n",
    "            image = cv2.flip(image, 0)  # Vertical flip\n",
    "            label = cv2.flip(label, 0)\n",
    "        elif flip_idx == 3:\n",
    "            image = cv2.flip(image, -1)  # Horizontal and vertical flip\n",
    "            label = cv2.flip(label, -1)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1) # Add channel dimension to label\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40e74fbc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.256584Z",
     "iopub.status.busy": "2024-11-24T08:09:17.255998Z",
     "iopub.status.idle": "2024-11-24T08:09:17.266203Z",
     "shell.execute_reply": "2024-11-24T08:09:17.265356Z"
    },
    "papermill": {
     "duration": 0.020529,
     "end_time": "2024-11-24T08:09:17.267958",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.247429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "# train_transformation = A.Compose([\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.VerticalFlip(p=0.5),\n",
    "#     A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "#     A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "#     A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()], p=0.35),\n",
    "#     A.CoarseDropout(p=0.2, max_height=15, max_width=15, fill_value=255),\n",
    "#     A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n",
    "# #     A.RandomShadow(p=0.1),\n",
    "#     A.ShiftScaleRotate(p=0.15, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n",
    "#     A.RandomCrop((img_resize, img_resize)),\n",
    "#     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "    \n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16a672c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.283656Z",
     "iopub.status.busy": "2024-11-24T08:09:17.283333Z",
     "iopub.status.idle": "2024-11-24T08:09:17.289066Z",
     "shell.execute_reply": "2024-11-24T08:09:17.288258Z"
    },
    "papermill": {
     "duration": 0.015524,
     "end_time": "2024-11-24T08:09:17.290746",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.275222",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "# generator = torch.Generator().manual_seed(7)\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "train_dataset = Subset(dataset, range(train_size))\n",
    "val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "train_dataset = AugmentDataset(train_dataset, transform=train_transformation, length_multiplier=1)\n",
    "val_dataset = AugmentDataset(val_dataset, transform=val_transformation)\n",
    "# train_dataset = CustomDataset(train_dataset, transform=train_transformation)\n",
    "# val_dataset = CustomDataset(val_dataset, transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "525a07a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.306830Z",
     "iopub.status.busy": "2024-11-24T08:09:17.306538Z",
     "iopub.status.idle": "2024-11-24T08:09:17.333069Z",
     "shell.execute_reply": "2024-11-24T08:09:17.332172Z"
    },
    "papermill": {
     "duration": 0.036594,
     "end_time": "2024-11-24T08:09:17.335042",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.298448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(img_dir=\"/kaggle/input/bkai-igh-neopolyp/test/test\", resize=img_resize, transform=val_transformation)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4239c82",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.351382Z",
     "iopub.status.busy": "2024-11-24T08:09:17.351076Z",
     "iopub.status.idle": "2024-11-24T08:09:17.356633Z",
     "shell.execute_reply": "2024-11-24T08:09:17.355825Z"
    },
    "papermill": {
     "duration": 0.01536,
     "end_time": "2024-11-24T08:09:17.358273",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.342913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ef7b70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.374303Z",
     "iopub.status.busy": "2024-11-24T08:09:17.373768Z",
     "iopub.status.idle": "2024-11-24T08:09:17.378540Z",
     "shell.execute_reply": "2024-11-24T08:09:17.377642Z"
    },
    "papermill": {
     "duration": 0.014824,
     "end_time": "2024-11-24T08:09:17.380380",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.365556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def visualize_samples(train_loader, val_loader, test_loader, unorm, num_samples=3):\n",
    "#     def show_images(images, labels=None, title=\"\"):\n",
    "#         fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "#         if len(images) == 1:\n",
    "#             axes = [axes]\n",
    "#         for i, img in enumerate(images):\n",
    "#             img = unorm(img)\n",
    "#             img = img.permute(1, 2, 0).cpu().numpy()\n",
    "#             axes[i].imshow(img)\n",
    "#             if labels is not None:\n",
    "#                 axes[i].imshow(labels[i].squeeze().cpu().numpy(), alpha=0.3, cmap='jet')\n",
    "#             axes[i].axis('off')\n",
    "#         fig.suptitle(title)\n",
    "#         plt.show()\n",
    "\n",
    "#     # Visualize train samples\n",
    "#     train_images, train_labels = next(iter(train_loader))\n",
    "#     show_images(train_images[:num_samples], train_labels[:num_samples], title=\"Train Samples\")\n",
    "\n",
    "#     # Visualize validation samples\n",
    "#     val_images, val_labels = next(iter(val_loader))\n",
    "#     show_images(val_images[:num_samples], val_labels[:num_samples], title=\"Validation Samples\")\n",
    "\n",
    "#     # Visualize test samples\n",
    "#     test_images, _, _, _ = next(iter(test_loader))\n",
    "#     show_images(test_images[:num_samples], title=\"Test Samples\")\n",
    "\n",
    "# visualize_samples(train_loader, val_loader, test_loader, unorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0832c89",
   "metadata": {
    "papermill": {
     "duration": 0.007125,
     "end_time": "2024-11-24T08:09:17.395076",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.387951",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e089790b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.411268Z",
     "iopub.status.busy": "2024-11-24T08:09:17.410953Z",
     "iopub.status.idle": "2024-11-24T08:09:17.415396Z",
     "shell.execute_reply": "2024-11-24T08:09:17.414545Z"
    },
    "papermill": {
     "duration": 0.014739,
     "end_time": "2024-11-24T08:09:17.417051",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.402312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class DoubleConv(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DoubleConv, self).__init__()\n",
    "#         self.double_conv = nn.Sequential(\n",
    "#             nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.LeakyReLU(inplace=True),\n",
    "#             nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "#             nn.BatchNorm2d(out_channels),\n",
    "#             nn.LeakyReLU(inplace=True),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         return self.double_conv(x)\n",
    "    \n",
    "    \n",
    "# class DownBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels):\n",
    "#         super(DownBlock, self).__init__()\n",
    "#         self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "#         self.down_sample = nn.MaxPool2d(2)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         skip_out = self.double_conv(x)\n",
    "#         down_out = self.down_sample(skip_out)\n",
    "#         return (down_out, skip_out)\n",
    "\n",
    "    \n",
    "# class UpBlock(nn.Module):\n",
    "#     def __init__(self, in_channels, out_channels, up_sample_mode):\n",
    "#         super(UpBlock, self).__init__()\n",
    "#         if up_sample_mode == 'conv_transpose':\n",
    "#             if out_channels*4 == in_channels:\n",
    "#                 self.up_sample = nn.ConvTranspose2d(in_channels-out_channels*2, in_channels-out_channels*2, kernel_size=2, stride=2) \n",
    "#             else:\n",
    "#                 self.up_sample = nn.ConvTranspose2d(in_channels-out_channels, in_channels-out_channels, kernel_size=2, stride=2)\n",
    "#         else:\n",
    "#             self.up_sample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "#         self.double_conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "#     def forward(self, down_input, skip_input):\n",
    "# #         print(\"down\", down_input.shape)\n",
    "# #         print(\"skip\", skip_input.shape)\n",
    "#         x = self.up_sample(down_input)\n",
    "# #         print(\"x\",x.shape)\n",
    "#         x = torch.cat([x, skip_input], dim=1)\n",
    "#         return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6c548ab5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.432865Z",
     "iopub.status.busy": "2024-11-24T08:09:17.432276Z",
     "iopub.status.idle": "2024-11-24T08:09:17.436356Z",
     "shell.execute_reply": "2024-11-24T08:09:17.435651Z"
    },
    "papermill": {
     "duration": 0.013785,
     "end_time": "2024-11-24T08:09:17.438041",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.424256",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ResUnet\n",
    "# class PolypModel(nn.Module):\n",
    "#     def __init__(self, out_classes=3, up_sample_mode='conv_transpose'):\n",
    "#         super().__init__()\n",
    "#         self.out_classes = out_classes\n",
    "#         self.backbone = timm.create_model(\"resnet152\", pretrained=True, features_only=True)\n",
    "# #         self.down_conv1 = DownBlock(3, 64)\n",
    "#         self.down_conv1 = DownBlock(64, 128)\n",
    "#         self.down_conv2 = DownBlock(256, 512)\n",
    "#         self.down_conv3 = DownBlock(512, 1024)\n",
    "#         self.down_conv4 = DownBlock(1024, 2048)\n",
    "#         self.up_sample_mode = up_sample_mode\n",
    "#         self.block_neck = DoubleConv(2048, 1024)\n",
    "#         self.block_up1 = UpBlock(1024+1024, 512,self.up_sample_mode)\n",
    "#         self.block_up2 = UpBlock(512+512, 256,self.up_sample_mode)\n",
    "#         self.block_up3 = UpBlock(256+256, 128,self.up_sample_mode)\n",
    "#         self.block_up4 = UpBlock(128+64, 64,self.up_sample_mode)\n",
    "#         self.conv_last = nn.Conv2d(64, out_classes, kernel_size=1)\n",
    "#         self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\")\n",
    "#         self.final_activation = nn.Softmax(dim=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x1, x2, x3, x4, x5 = self.backbone(x)\n",
    "#         x = self.block_neck(x5) # x (B, 1024, 8, 8)\n",
    "#         x = self.block_up1(x, x4)\n",
    "#         x = self.block_up2(x, x3)\n",
    "#         x = self.block_up3(x, x2)\n",
    "#         x = self.block_up4(x, x1 )\n",
    "#         x = self.conv_last(x)\n",
    "#         x = self.upsample(x)\n",
    "#         x = self.final_activation(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ccd476",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:17.454661Z",
     "iopub.status.busy": "2024-11-24T08:09:17.453907Z",
     "iopub.status.idle": "2024-11-24T08:09:22.446926Z",
     "shell.execute_reply": "2024-11-24T08:09:22.446137Z"
    },
    "papermill": {
     "duration": 5.00376,
     "end_time": "2024-11-24T08:09:22.449102",
     "exception": false,
     "start_time": "2024-11-24T08:09:17.445342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet152-b121ed2d.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-b121ed2d.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 230M/230M [00:02<00:00, 90.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "# model = PolypModel()\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"timm-resnest200e\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "266abd6f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:22.468817Z",
     "iopub.status.busy": "2024-11-24T08:09:22.468448Z",
     "iopub.status.idle": "2024-11-24T08:09:22.472382Z",
     "shell.execute_reply": "2024-11-24T08:09:22.471657Z"
    },
    "papermill": {
     "duration": 0.015747,
     "end_time": "2024-11-24T08:09:22.474008",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.458261",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/kaggle/input/unetplusplus-resnet152/model.pth')\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a0990353",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:22.493033Z",
     "iopub.status.busy": "2024-11-24T08:09:22.492753Z",
     "iopub.status.idle": "2024-11-24T08:09:22.497561Z",
     "shell.execute_reply": "2024-11-24T08:09:22.496891Z"
    },
    "papermill": {
     "duration": 0.016204,
     "end_time": "2024-11-24T08:09:22.499184",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.482980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c678a4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:22.517871Z",
     "iopub.status.busy": "2024-11-24T08:09:22.517555Z",
     "iopub.status.idle": "2024-11-24T08:09:22.521133Z",
     "shell.execute_reply": "2024-11-24T08:09:22.520291Z"
    },
    "papermill": {
     "duration": 0.015101,
     "end_time": "2024-11-24T08:09:22.522830",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.507729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del train_dataset\n",
    "# del val_dataset\n",
    "# del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3ee01",
   "metadata": {
    "papermill": {
     "duration": 0.00889,
     "end_time": "2024-11-24T08:09:22.540449",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.531559",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ae3fcf",
   "metadata": {
    "papermill": {
     "duration": 0.008477,
     "end_time": "2024-11-24T08:09:22.557710",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.549233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define Dice loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0af01ed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:22.576912Z",
     "iopub.status.busy": "2024-11-24T08:09:22.576527Z",
     "iopub.status.idle": "2024-11-24T08:09:26.115564Z",
     "shell.execute_reply": "2024-11-24T08:09:26.114672Z"
    },
    "papermill": {
     "duration": 3.550683,
     "end_time": "2024-11-24T08:09:26.117430",
     "exception": false,
     "start_time": "2024-11-24T08:09:22.566747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtu7pham7\u001b[0m (\u001b[33mhustcollab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241124_080923-hd38xsfw\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdeep-breeze-61\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment/runs/hd38xsfw\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(\n",
    "    # set the wandb project where this run will be logged\n",
    "#     project= \"PolypSegment\", \n",
    "    key = \"e02f7703b40a2b3e0ab4801d4cb1d86b3b7327a6\",\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"PolypSegment\",\n",
    "    config={\n",
    "        # \"model\" : \"Unet\",\n",
    "        \"init_learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_functions\": [\"CrossEntropy\", \"Dice\"],\n",
    "        \"alpha\":alpha,\n",
    "        \"imsize\": img_resize\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the model to WandB\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af5f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, class_weights = None, gamma=2, ignore_index=None):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.class_weights = class_weights\n",
    "        self.gamma = gamma\n",
    "        self.ignore_index = ignore_index\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        logpt = -F.cross_entropy(inputs, targets, reduction='none', ignore_index=self.ignore_index)\n",
    "        pt = torch.exp(logpt)\n",
    "        loss = self.class_weights * ((1 - pt) ** self.gamma) * logpt\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "befa1630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:26.139102Z",
     "iopub.status.busy": "2024-11-24T08:09:26.138144Z",
     "iopub.status.idle": "2024-11-24T08:09:26.440676Z",
     "shell.execute_reply": "2024-11-24T08:09:26.439732Z"
    },
    "papermill": {
     "duration": 0.315327,
     "end_time": "2024-11-24T08:09:26.442808",
     "exception": false,
     "start_time": "2024-11-24T08:09:26.127481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "criterion_ce = nn.CrossEntropyLoss()\n",
    "criterion_dice = smp.losses.DiceLoss(mode='multiclass')\n",
    "best_val_loss = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd0f3975",
   "metadata": {
    "papermill": {
     "duration": 0.009308,
     "end_time": "2024-11-24T08:09:26.462229",
     "exception": false,
     "start_time": "2024-11-24T08:09:26.452921",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make use of learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a966e1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:26.482870Z",
     "iopub.status.busy": "2024-11-24T08:09:26.481974Z",
     "iopub.status.idle": "2024-11-24T08:09:26.492794Z",
     "shell.execute_reply": "2024-11-24T08:09:26.491782Z"
    },
    "papermill": {
     "duration": 0.022904,
     "end_time": "2024-11-24T08:09:26.494476",
     "exception": false,
     "start_time": "2024-11-24T08:09:26.471572",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "scaler = GradScaler()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize the scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',                 # We want to minimize the validation loss\n",
    "    factor=0.1,                 # Reduce LR by a factor of 0.5\n",
    "    patience=0,                 # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True,               # Print a message when LR is updated\n",
    "    threshold=0.0001,           # Threshold for measuring the new optimum\n",
    "    threshold_mode='rel',       # Mode for threshold\n",
    "    cooldown=0,                 # Number of epochs to wait before resuming normal operation after LR has been reduced\n",
    "    min_lr=1e-6                 # Lower bound on the learning rate\n",
    ")\n",
    "\n",
    "scheduler2 = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "adb53e93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:09:26.514513Z",
     "iopub.status.busy": "2024-11-24T08:09:26.514253Z",
     "iopub.status.idle": "2024-11-24T08:28:57.354371Z",
     "shell.execute_reply": "2024-11-24T08:28:57.353476Z"
    },
    "papermill": {
     "duration": 1170.865152,
     "end_time": "2024-11-24T08:28:57.369123",
     "exception": false,
     "start_time": "2024-11-24T08:09:26.503971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.2663187640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   5%|â–Œ         | 1/20 [01:09<22:01, 69.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/20], Loss: 0.3378334556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|â–ˆ         | 2/20 [02:09<19:12, 64.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/20], Loss: 0.3002601053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  15%|â–ˆâ–Œ        | 3/20 [03:09<17:33, 61.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/20], Loss: 0.2994723288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [05:04<14:47, 59.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/20], Loss: 0.3357010782\n",
      "Epoch [6/20], Loss: 0.2164779093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [06:03<13:47, 59.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/20], Loss: 0.1993949200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [07:02<12:48, 59.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/20], Loss: 0.1831545745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [08:58<10:42, 58.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/20], Loss: 0.1852125334\n",
      "Epoch [10/20], Loss: 0.1732013651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 11/20 [10:54<08:42, 58.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/20], Loss: 0.1801971155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 12/20 [11:51<07:42, 57.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/20], Loss: 0.1877907068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 13/20 [12:48<06:42, 57.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/20], Loss: 0.1955949047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 14/20 [13:45<05:43, 57.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/20], Loss: 0.1835420983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 15/20 [14:42<04:46, 57.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/20], Loss: 0.1801815778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 16/20 [15:39<03:49, 57.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/20], Loss: 0.1860399800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 17/20 [16:36<02:51, 57.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/20], Loss: 0.1819254969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 18/20 [17:33<01:54, 57.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/20], Loss: 0.1764565366\n",
      "Epoch [19/20], Loss: 0.1586084004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 20/20 [19:30<00:00, 58.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/20], Loss: 0.1809272873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_dice = criterion_dice(outputs, labels)\n",
    "            loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss_ce = criterion_ce(outputs, labels)\n",
    "                loss_dice = criterion_dice(outputs, labels)\n",
    "                loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    epoch_bar.update(1)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader), 'Learning_rate' : current_lr})\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a6fee87",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:28:57.394591Z",
     "iopub.status.busy": "2024-11-24T08:28:57.393680Z",
     "iopub.status.idle": "2024-11-24T08:28:58.279010Z",
     "shell.execute_reply": "2024-11-24T08:28:58.278209Z"
    },
    "papermill": {
     "duration": 0.900439,
     "end_time": "2024-11-24T08:28:58.281063",
     "exception": false,
     "start_time": "2024-11-24T08:28:57.380624",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4093892069.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/kaggle/working/model.pth')\n"
     ]
    }
   ],
   "source": [
    "# model = smp.UnetPlusPlus(\n",
    "#     encoder_name=\"resnet34\",        \n",
    "#     # encoder_weights=\"imagenet\",     \n",
    "#     in_channels=3,                  \n",
    "#     classes=3     \n",
    "# )\n",
    "# model = PolypModel()\n",
    "# checkpoint = torch.load('/kaggle/input/model-polyp/colorization_model.pth')\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# model = model.to(device)\n",
    "checkpoint = torch.load('/kaggle/working/model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4d4909e3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:28:58.305693Z",
     "iopub.status.busy": "2024-11-24T08:28:58.305357Z",
     "iopub.status.idle": "2024-11-24T08:29:06.006623Z",
     "shell.execute_reply": "2024-11-24T08:29:06.005657Z"
    },
    "papermill": {
     "duration": 7.715697,
     "end_time": "2024-11-24T08:29:06.008700",
     "exception": false,
     "start_time": "2024-11-24T08:28:58.293003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31018590927124023\n",
      "0.3012106418609619\n",
      "0.2889310419559479\n",
      "0.25360262393951416\n",
      "0.3469126224517822\n",
      "0.31575465202331543\n",
      "0.06808605045080185\n",
      "Loss: 0.2692405060\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        \n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            # loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_dice = criterion_dice(outputs, labels)\n",
    "            # loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "            print(loss_dice.item())\n",
    "        val_loss += loss_dice.item()\n",
    "print(f\"Loss: {val_loss/len(val_loader):.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a7b43a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:29:06.035858Z",
     "iopub.status.busy": "2024-11-24T08:29:06.035153Z",
     "iopub.status.idle": "2024-11-24T08:29:06.039178Z",
     "shell.execute_reply": "2024-11-24T08:29:06.038432Z"
    },
    "papermill": {
     "duration": 0.019039,
     "end_time": "2024-11-24T08:29:06.040925",
     "exception": false,
     "start_time": "2024-11-24T08:29:06.021886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# shutil.rmtree('prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63dbe6bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:29:06.065008Z",
     "iopub.status.busy": "2024-11-24T08:29:06.064729Z",
     "iopub.status.idle": "2024-11-24T08:29:07.119462Z",
     "shell.execute_reply": "2024-11-24T08:29:07.118196Z"
    },
    "papermill": {
     "duration": 1.069176,
     "end_time": "2024-11-24T08:29:07.121581",
     "exception": false,
     "start_time": "2024-11-24T08:29:06.052405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee4bd7",
   "metadata": {
    "papermill": {
     "duration": 0.011651,
     "end_time": "2024-11-24T08:29:07.145905",
     "exception": false,
     "start_time": "2024-11-24T08:29:07.134254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Testset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdac16fa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:29:07.172239Z",
     "iopub.status.busy": "2024-11-24T08:29:07.171365Z",
     "iopub.status.idle": "2024-11-24T08:29:07.178051Z",
     "shell.execute_reply": "2024-11-24T08:29:07.177273Z"
    },
    "papermill": {
     "duration": 0.021695,
     "end_time": "2024-11-24T08:29:07.179710",
     "exception": false,
     "start_time": "2024-11-24T08:29:07.158015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Smoothed_img(image):\n",
    "    resized_image = image\n",
    "    smoothed_image = cv2.GaussianBlur(resized_image, (15, 15), 0)\n",
    "    red_pixels = (smoothed_image[:, :, 2] > 100)\n",
    "    green_pixels = (smoothed_image[:, :, 1] > 100)\n",
    "    black_pixels = ~(red_pixels | green_pixels)\n",
    "    smoothed_image[red_pixels] = [0, 0, 255]\n",
    "    smoothed_image[green_pixels] = [0, 255, 0]\n",
    "    smoothed_image[black_pixels] = [0, 0, 0]\n",
    "\n",
    "    # pixel_values = np.array(smoothed_image)\n",
    "    # unique_values = np.unique(pixel_values)\n",
    "    # print(unique_values)\n",
    "    return smoothed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a449c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-24T08:29:07.204741Z",
     "iopub.status.busy": "2024-11-24T08:29:07.204026Z",
     "iopub.status.idle": "2024-11-24T08:29:08.706136Z",
     "shell.execute_reply": "2024-11-24T08:29:08.704932Z"
    },
    "papermill": {
     "duration": 1.515927,
     "end_time": "2024-11-24T08:29:08.707570",
     "exception": true,
     "start_time": "2024-11-24T08:29:07.191643",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "boolean index did not match indexed array along dimension 2; dimension is 3 but corresponding boolean dimension is 256",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m outputs \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m      6\u001b[0m outputs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(outputs, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmask_to_rgb\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m w \u001b[38;5;241m=\u001b[39m w\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      9\u001b[0m h \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m, in \u001b[0;36mmask_to_rgb\u001b[0;34m(mask, color_dict)\u001b[0m\n\u001b[1;32m      5\u001b[0m output \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], mask\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m color_dict\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m----> 8\u001b[0m     \u001b[43moutput\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m color_dict[k]\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39muint8(output)\n",
      "\u001b[0;31mIndexError\u001b[0m: boolean index did not match indexed array along dimension 2; dimension is 3 but corresponding boolean dimension is 256"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image, h, w, name in test_loader:\n",
    "        outputs = model(image.to(device))\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        outputs = np.argmax(outputs, axis=0)\n",
    "        outputs = mask_to_rgb(outputs, color_dict)\n",
    "        w = w.item()\n",
    "        h = h.item()\n",
    "        new_size = (w, h)\n",
    "        resized_image = cv2.resize(outputs, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Smoothed_img(resized_image)\n",
    "        cv2.imwrite(f\"prediction/{name[0]}.png\", resized_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e994ee",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-23T18:47:35.588465Z",
     "iopub.status.idle": "2024-11-23T18:47:35.588914Z",
     "shell.execute_reply": "2024-11-23T18:47:35.588699Z",
     "shell.execute_reply.started": "2024-11-23T18:47:35.588677Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        # print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0d1473",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10712bfa",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-23T18:47:35.590220Z",
     "iopub.status.idle": "2024-11-23T18:47:35.590662Z",
     "shell.execute_reply": "2024-11-23T18:47:35.590454Z",
     "shell.execute_reply.started": "2024-11-23T18:47:35.590432Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !mkdir -p /kaggle/working/prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d150474",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-11-23T18:47:35.592027Z",
     "iopub.status.idle": "2024-11-23T18:47:35.592525Z",
     "shell.execute_reply": "2024-11-23T18:47:35.592319Z",
     "shell.execute_reply.started": "2024-11-23T18:47:35.592295Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def inference(model, test_loader, device, color_dict, output_dir=\"inference\"):\n",
    "#     model.eval()\n",
    "#     os.makedirs(output_dir, exist_ok=True)\n",
    "#     with torch.no_grad():\n",
    "#         for image, h, w, name in test_loader:\n",
    "#             outputs = model(image.to(device))\n",
    "#             outputs = outputs.squeeze()\n",
    "#             outputs = np.argmax(outputs.cpu().numpy(), axis=0)\n",
    "#             outputs = mask_to_rgb(outputs, color_dict)\n",
    "#             w = w.item()\n",
    "#             h = h.item()\n",
    "#             new_size = (w, h)\n",
    "#             resized_image = cv2.resize(outputs, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "#             resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "#             resized_image = Smoothed_img(resized_image)\n",
    "#             cv2.imwrite(f\"{output_dir}/{name[0]}.png\", resized_image)\n",
    "\n",
    "# inference(model, test_loader, device, color_dict)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 6152584,
     "sourceId": 9996387,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1224.190835,
   "end_time": "2024-11-24T08:29:12.208717",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-24T08:08:48.017882",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
