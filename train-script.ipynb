{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb910b3e",
   "metadata": {
    "papermill": {
     "duration": 0.006634,
     "end_time": "2024-11-25T12:48:19.621731",
     "exception": false,
     "start_time": "2024-11-25T12:48:19.615097",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "061d3a6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:19.635801Z",
     "iopub.status.busy": "2024-11-25T12:48:19.635495Z",
     "iopub.status.idle": "2024-11-25T12:48:33.851205Z",
     "shell.execute_reply": "2024-11-25T12:48:33.850080Z"
    },
    "papermill": {
     "duration": 14.22438,
     "end_time": "2024-11-25T12:48:33.853079",
     "exception": false,
     "start_time": "2024-11-25T12:48:19.628699",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b980a8c6",
   "metadata": {
    "papermill": {
     "duration": 0.006008,
     "end_time": "2024-11-25T12:48:33.865481",
     "exception": false,
     "start_time": "2024-11-25T12:48:33.859473",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1e9d07",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:33.878462Z",
     "iopub.status.busy": "2024-11-25T12:48:33.878132Z",
     "iopub.status.idle": "2024-11-25T12:48:42.870819Z",
     "shell.execute_reply": "2024-11-25T12:48:42.870141Z"
    },
    "papermill": {
     "duration": 9.00146,
     "end_time": "2024-11-25T12:48:42.872775",
     "exception": false,
     "start_time": "2024-11-25T12:48:33.871315",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.17). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, random_split, DataLoader, Subset\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "import os\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.optim as optim\n",
    "from torch.amp import autocast, GradScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d898333",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:42.886529Z",
     "iopub.status.busy": "2024-11-25T12:48:42.886256Z",
     "iopub.status.idle": "2024-11-25T12:48:43.915816Z",
     "shell.execute_reply": "2024-11-25T12:48:43.914928Z"
    },
    "papermill": {
     "duration": 1.038256,
     "end_time": "2024-11-25T12:48:43.917556",
     "exception": false,
     "start_time": "2024-11-25T12:48:42.879300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-1a4f79bb-3088-616f-6ae0-2bb71b2fca42)\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3c46eba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:43.931670Z",
     "iopub.status.busy": "2024-11-25T12:48:43.931356Z",
     "iopub.status.idle": "2024-11-25T12:48:43.992728Z",
     "shell.execute_reply": "2024-11-25T12:48:43.991840Z"
    },
    "papermill": {
     "duration": 0.070436,
     "end_time": "2024-11-25T12:48:43.994399",
     "exception": false,
     "start_time": "2024-11-25T12:48:43.923963",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089ec8bb",
   "metadata": {
    "papermill": {
     "duration": 0.005874,
     "end_time": "2024-11-25T12:48:44.006509",
     "exception": false,
     "start_time": "2024-11-25T12:48:44.000635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e188c76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:44.019721Z",
     "iopub.status.busy": "2024-11-25T12:48:44.019454Z",
     "iopub.status.idle": "2024-11-25T12:48:45.000874Z",
     "shell.execute_reply": "2024-11-25T12:48:45.000002Z"
    },
    "papermill": {
     "duration": 0.990029,
     "end_time": "2024-11-25T12:48:45.002763",
     "exception": false,
     "start_time": "2024-11-25T12:48:44.012734",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_path = \"/kaggle/input/bkai-igh-neopolyp/train/train/\"\n",
    "image_path = []\n",
    "TRAIN_DIR = '/kaggle/input/bkai-igh-neopolyp/train/train'\n",
    "for root, dirs, files in os.walk(TRAIN_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        image_path.append(path)\n",
    "        \n",
    "len(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ed8263",
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:45.017203Z",
     "iopub.status.busy": "2024-11-25T12:48:45.016507Z",
     "iopub.status.idle": "2024-11-25T12:48:45.020647Z",
     "shell.execute_reply": "2024-11-25T12:48:45.020016Z"
    },
    "papermill": {
     "duration": 0.012789,
     "end_time": "2024-11-25T12:48:45.022152",
     "exception": false,
     "start_time": "2024-11-25T12:48:45.009363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import os\n",
    "# import cv2\n",
    "# import numpy as np\n",
    "\n",
    "# def calculate_mean_image_size(image_dir):\n",
    "#     widths = []\n",
    "#     heights = []\n",
    "\n",
    "#     for filename in os.listdir(image_dir):\n",
    "#         if filename.lower().endswith(('.png', '.jpg', '.jpeg', '.tiff', '.bmp', '.gif')):\n",
    "#             img_path = os.path.join(image_dir, filename)\n",
    "#             image = cv2.imread(img_path)\n",
    "#             if image is not None:\n",
    "#                 h, w = image.shape[:2]\n",
    "#                 heights.append(h)\n",
    "#                 widths.append(w)\n",
    "#             else:\n",
    "#                 print(f\"Warning: Unable to read image {img_path}\")\n",
    "\n",
    "#     mean_width = int(np.mean(widths))\n",
    "#     mean_height = int(np.mean(heights))\n",
    "#     median_width = int(np.median(widths))\n",
    "#     median_height = int(np.median(heights))\n",
    "\n",
    "#     print(f\"Number of images: {len(widths)}\")\n",
    "#     print(f\"Mean Width: {mean_width}, Mean Height: {mean_height}\")\n",
    "#     print(f\"Median Width: {median_width}, Median Height: {median_height}\")\n",
    "\n",
    "#     return mean_width, mean_height, widths, heights\n",
    "\n",
    "# # Example usage:\n",
    "# image_directory = '/kaggle/input/bkai-igh-neopolyp/test/test'\n",
    "# mean_w, mean_h, widths, heights = calculate_mean_image_size(image_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10ecaa1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:45.035756Z",
     "iopub.status.busy": "2024-11-25T12:48:45.035073Z",
     "iopub.status.idle": "2024-11-25T12:48:45.038913Z",
     "shell.execute_reply": "2024-11-25T12:48:45.038120Z"
    },
    "papermill": {
     "duration": 0.012198,
     "end_time": "2024-11-25T12:48:45.040497",
     "exception": false,
     "start_time": "2024-11-25T12:48:45.028299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_dimension_distribution(widths, heights):\n",
    "#     plt.figure(figsize=(12, 5))\n",
    "\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.hist(widths, bins=20, color='skyblue')\n",
    "#     plt.title('Width Distribution')\n",
    "#     plt.xlabel('Width')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.hist(heights, bins=20, color='salmon')\n",
    "#     plt.title('Height Distribution')\n",
    "#     plt.xlabel('Height')\n",
    "#     plt.ylabel('Frequency')\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# # After collecting widths and heights in the function above:\n",
    "# plot_dimension_distribution(widths, heights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea0e13f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:45.054192Z",
     "iopub.status.busy": "2024-11-25T12:48:45.053923Z",
     "iopub.status.idle": "2024-11-25T12:48:46.041459Z",
     "shell.execute_reply": "2024-11-25T12:48:46.040478Z"
    },
    "papermill": {
     "duration": 0.996362,
     "end_time": "2024-11-25T12:48:46.043331",
     "exception": false,
     "start_time": "2024-11-25T12:48:45.046969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_path = []\n",
    "TRAIN_MASK_DIR = '/kaggle/input/bkai-igh-neopolyp/train_gt/train_gt'\n",
    "for root, dirs, files in os.walk(TRAIN_MASK_DIR):\n",
    "    for file in files:\n",
    "        path = os.path.join(root,file)\n",
    "        mask_path.append(path)\n",
    "        \n",
    "len(mask_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6b51590",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.058529Z",
     "iopub.status.busy": "2024-11-25T12:48:46.057825Z",
     "iopub.status.idle": "2024-11-25T12:48:46.075211Z",
     "shell.execute_reply": "2024-11-25T12:48:46.074393Z"
    },
    "papermill": {
     "duration": 0.02685,
     "end_time": "2024-11-25T12:48:46.076937",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.050087",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TrainDataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, resize=None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.resize = resize\n",
    "        self.transform = transform\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def read_mask(self, mask_path):\n",
    "        image = cv2.imread(mask_path)\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "        lower_red1 = np.array([0, 100, 20])\n",
    "        upper_red1 = np.array([10, 255, 255])\n",
    "        lower_red2 = np.array([160,100,20])\n",
    "        upper_red2 = np.array([179,255,255])\n",
    "        \n",
    "        lower_mask_red = cv2.inRange(image, lower_red1, upper_red1)\n",
    "        upper_mask_red = cv2.inRange(image, lower_red2, upper_red2)\n",
    "        \n",
    "        red_mask = lower_mask_red + upper_mask_red\n",
    "        red_mask[red_mask != 0] = 1\n",
    "\n",
    "        green_mask = cv2.inRange(image, (36, 25, 25), (70, 255, 255))\n",
    "        green_mask[green_mask != 0] = 2\n",
    "\n",
    "        full_mask = cv2.bitwise_or(red_mask, green_mask)\n",
    "        full_mask = np.expand_dims(full_mask, axis=-1) \n",
    "        full_mask = full_mask.astype(np.uint8)\n",
    "        \n",
    "        return full_mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        label_path = os.path.join(self.label_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)  #  BGR\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # Convert to RGB\n",
    "        label = self.read_mask(label_path)  \n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "    \n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, img_dir=\"path/to/data\", resize = None, transform=None):\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.resize = resize\n",
    "        self.images = os.listdir(self.img_dir)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.images[idx])\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        height, width, channels = image.shape\n",
    "        image = cv2.resize(image, self.resize, interpolation=cv2.INTER_AREA)\n",
    "        name =  os.path.basename(img_path)\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image)\n",
    "            image = transformed[\"image\"]\n",
    "        return image, height, width, name[:-5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bac73e",
   "metadata": {
    "papermill": {
     "duration": 0.006019,
     "end_time": "2024-11-25T12:48:46.089361",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.083342",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb34aa4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.103304Z",
     "iopub.status.busy": "2024-11-25T12:48:46.102615Z",
     "iopub.status.idle": "2024-11-25T12:48:46.106718Z",
     "shell.execute_reply": "2024-11-25T12:48:46.105971Z"
    },
    "papermill": {
     "duration": 0.012999,
     "end_time": "2024-11-25T12:48:46.108663",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.095664",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_resize = (256, 256)\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "alpha = 0.3 # Weight of cross entropy loss \n",
    "class_weights = [0.05, 0.25, 0.70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c952d1f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.130906Z",
     "iopub.status.busy": "2024-11-25T12:48:46.130639Z",
     "iopub.status.idle": "2024-11-25T12:48:46.135238Z",
     "shell.execute_reply": "2024-11-25T12:48:46.134363Z"
    },
    "papermill": {
     "duration": 0.016604,
     "end_time": "2024-11-25T12:48:46.137349",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.120745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = TrainDataset(img_dir= TRAIN_DIR,\n",
    "                             label_dir= TRAIN_MASK_DIR,\n",
    "                             resize= img_resize,\n",
    "                             transform = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3dda3c",
   "metadata": {
    "papermill": {
     "duration": 0.005995,
     "end_time": "2024-11-25T12:48:46.149978",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.143983",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d5aadb3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.163461Z",
     "iopub.status.busy": "2024-11-25T12:48:46.163127Z",
     "iopub.status.idle": "2024-11-25T12:48:46.170421Z",
     "shell.execute_reply": "2024-11-25T12:48:46.169614Z"
    },
    "papermill": {
     "duration": 0.015891,
     "end_time": "2024-11-25T12:48:46.172051",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.156160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AugmentDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None, length_multiplier=1):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.length_multiplier = length_multiplier\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx % len(self.dataset)\n",
    "        image, label = self.dataset[actual_idx]\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1)\n",
    "        return image, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * self.length_multiplier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c3a666d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.185469Z",
     "iopub.status.busy": "2024-11-25T12:48:46.185223Z",
     "iopub.status.idle": "2024-11-25T12:48:46.191663Z",
     "shell.execute_reply": "2024-11-25T12:48:46.190707Z"
    },
    "papermill": {
     "duration": 0.015171,
     "end_time": "2024-11-25T12:48:46.193390",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.178219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataset, transform=None):\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset) * 4  # Four copies per image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        actual_idx = idx // 4\n",
    "        flip_idx = idx % 4\n",
    "\n",
    "        image, label = self.dataset[actual_idx]\n",
    "\n",
    "        # Apply flips based on flip_idx\n",
    "        if flip_idx == 1:\n",
    "            image = cv2.flip(image, 1)  # Horizontal flip\n",
    "            label = cv2.flip(label, 1)\n",
    "        elif flip_idx == 2:\n",
    "            image = cv2.flip(image, 0)  # Vertical flip\n",
    "            label = cv2.flip(label, 0)\n",
    "        elif flip_idx == 3:\n",
    "            image = cv2.flip(image, -1)  # Horizontal and vertical flip\n",
    "            label = cv2.flip(label, -1)\n",
    "\n",
    "        if self.transform:\n",
    "            transformed = self.transform(image=image, mask=label)\n",
    "            image = transformed['image'].float()\n",
    "            label = transformed['mask'].float()\n",
    "            label = label.permute(2, 0, 1) # Add channel dimension to label\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "842869a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.207572Z",
     "iopub.status.busy": "2024-11-25T12:48:46.206826Z",
     "iopub.status.idle": "2024-11-25T12:48:46.220608Z",
     "shell.execute_reply": "2024-11-25T12:48:46.219842Z"
    },
    "papermill": {
     "duration": 0.022423,
     "end_time": "2024-11-25T12:48:46.222129",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.199706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_transformation = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "    A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "val_transformation = A.Compose([\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406),std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "# train_transformation = A.Compose([\n",
    "#     A.HorizontalFlip(p=0.5),\n",
    "#     A.VerticalFlip(p=0.5),\n",
    "#     A.RandomGamma (gamma_limit=(70, 130), always_apply=False, p=0.2),\n",
    "#     A.RGBShift(p=0.3, r_shift_limit=10, g_shift_limit=10, b_shift_limit=10),\n",
    "#     A.OneOf([A.Blur(), A.GaussianBlur(), A.GlassBlur(), A.MotionBlur(), A.GaussNoise(), A.Sharpen(), A.MedianBlur(), A.MultiplicativeNoise()], p=0.35),\n",
    "#     A.CoarseDropout(p=0.2, max_height=15, max_width=15, fill_value=255),\n",
    "#     A.RandomSnow(snow_point_lower=0.1, snow_point_upper=0.15, brightness_coeff=1.5, p=0.09),\n",
    "# #     A.RandomShadow(p=0.1),\n",
    "#     A.ShiftScaleRotate(p=0.15, border_mode=cv2.BORDER_CONSTANT, shift_limit=0.15, scale_limit=0.15),\n",
    "#     A.RandomCrop((img_resize, img_resize)),\n",
    "#     A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "#     ToTensorV2(),\n",
    "# ])\n",
    "class UnNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
    "        Returns:\n",
    "            Tensor: Normalized image.\n",
    "        \"\"\"\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "            # The normalize code -> t.sub_(m).div_(s)\n",
    "        return tensor\n",
    "    \n",
    "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4ad1893b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.236073Z",
     "iopub.status.busy": "2024-11-25T12:48:46.235537Z",
     "iopub.status.idle": "2024-11-25T12:48:46.250423Z",
     "shell.execute_reply": "2024-11-25T12:48:46.249612Z"
    },
    "papermill": {
     "duration": 0.024013,
     "end_time": "2024-11-25T12:48:46.252409",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.228396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the split sizes\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Randomly split the dataset\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size], generator=generator)\n",
    "# train_dataset = Subset(dataset, range(train_size))\n",
    "# val_dataset = Subset(dataset, range(train_size, train_size + val_size))\n",
    "train_dataset = AugmentDataset(train_dataset, transform=train_transformation, length_multiplier=1)\n",
    "val_dataset = AugmentDataset(val_dataset, transform=val_transformation)\n",
    "# train_dataset = CustomDataset(train_dataset, transform=train_transformation)\n",
    "# val_dataset = CustomDataset(val_dataset, transform=val_transformation)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "# test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3afd5b9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.273922Z",
     "iopub.status.busy": "2024-11-25T12:48:46.273608Z",
     "iopub.status.idle": "2024-11-25T12:48:46.328681Z",
     "shell.execute_reply": "2024-11-25T12:48:46.327876Z"
    },
    "papermill": {
     "duration": 0.066622,
     "end_time": "2024-11-25T12:48:46.330760",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.264138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_dataset = TestDataset(img_dir=\"/kaggle/input/bkai-igh-neopolyp/test/test\", resize=img_resize, transform=val_transformation)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b6fe468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.350450Z",
     "iopub.status.busy": "2024-11-25T12:48:46.349822Z",
     "iopub.status.idle": "2024-11-25T12:48:46.355865Z",
     "shell.execute_reply": "2024-11-25T12:48:46.355222Z"
    },
    "papermill": {
     "duration": 0.014933,
     "end_time": "2024-11-25T12:48:46.357461",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.342528",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 200, 200)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(val_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdfb6d71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.371487Z",
     "iopub.status.busy": "2024-11-25T12:48:46.370880Z",
     "iopub.status.idle": "2024-11-25T12:48:46.375771Z",
     "shell.execute_reply": "2024-11-25T12:48:46.375051Z"
    },
    "papermill": {
     "duration": 0.013549,
     "end_time": "2024-11-25T12:48:46.377327",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.363778",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def visualize_samples(train_loader, val_loader, test_loader, unorm, num_samples=3):\n",
    "#     def show_images(images, labels=None, title=\"\"):\n",
    "#         fig, axes = plt.subplots(1, len(images), figsize=(15, 5))\n",
    "#         if len(images) == 1:\n",
    "#             axes = [axes]\n",
    "#         for i, img in enumerate(images):\n",
    "#             img = unorm(img)\n",
    "#             img = img.permute(1, 2, 0).cpu().numpy()\n",
    "#             axes[i].imshow(img)\n",
    "#             if labels is not None:\n",
    "#                 axes[i].imshow(labels[i].squeeze().cpu().numpy(), alpha=0.3, cmap='jet')\n",
    "#             axes[i].axis('off')\n",
    "#         fig.suptitle(title)\n",
    "#         plt.show()\n",
    "\n",
    "#     # Visualize train samples\n",
    "#     train_images, train_labels = next(iter(train_loader))\n",
    "#     show_images(train_images[:num_samples], train_labels[:num_samples], title=\"Train Samples\")\n",
    "\n",
    "#     # Visualize validation samples\n",
    "#     val_images, val_labels = next(iter(val_loader))\n",
    "#     show_images(val_images[:num_samples], val_labels[:num_samples], title=\"Validation Samples\")\n",
    "\n",
    "#     # Visualize test samples\n",
    "#     test_images, _, _, _ = next(iter(test_loader))\n",
    "#     show_images(test_images[:num_samples], title=\"Test Samples\")\n",
    "\n",
    "# visualize_samples(train_loader, val_loader, test_loader, unorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053dcd44",
   "metadata": {
    "papermill": {
     "duration": 0.005989,
     "end_time": "2024-11-25T12:48:46.389620",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.383631",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f0797a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:46.403121Z",
     "iopub.status.busy": "2024-11-25T12:48:46.402815Z",
     "iopub.status.idle": "2024-11-25T12:48:47.750153Z",
     "shell.execute_reply": "2024-11-25T12:48:47.749429Z"
    },
    "papermill": {
     "duration": 1.356317,
     "end_time": "2024-11-25T12:48:47.752168",
     "exception": false,
     "start_time": "2024-11-25T12:48:46.395851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet50-19c8e357.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97.8M/97.8M [00:00<00:00, 445MB/s]\n"
     ]
    }
   ],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",        \n",
    "    encoder_weights=\"imagenet\",     \n",
    "    in_channels=3,                  \n",
    "    classes=3     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6da74940",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:47.767546Z",
     "iopub.status.busy": "2024-11-25T12:48:47.766981Z",
     "iopub.status.idle": "2024-11-25T12:48:47.770509Z",
     "shell.execute_reply": "2024-11-25T12:48:47.769724Z"
    },
    "papermill": {
     "duration": 0.012786,
     "end_time": "2024-11-25T12:48:47.772158",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.759372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint = torch.load('/kaggle/input/unetplusplus-resnest/model.pth')\n",
    "# model.load_state_dict(checkpoint['model'])\n",
    "# model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cdbbc947",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:47.786440Z",
     "iopub.status.busy": "2024-11-25T12:48:47.786163Z",
     "iopub.status.idle": "2024-11-25T12:48:47.790858Z",
     "shell.execute_reply": "2024-11-25T12:48:47.790063Z"
    },
    "papermill": {
     "duration": 0.013397,
     "end_time": "2024-11-25T12:48:47.792320",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.778923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "color_dict= {0: (0, 0, 0),\n",
    "             1: (255, 0, 0),\n",
    "             2: (0, 255, 0)}\n",
    "def mask_to_rgb(mask, color_dict):\n",
    "    output = np.zeros((mask.shape[0], mask.shape[1], 3))\n",
    "\n",
    "    for k in color_dict.keys():\n",
    "        output[mask==k] = color_dict[k]\n",
    "\n",
    "    return np.uint8(output)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4dbadeea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:47.806470Z",
     "iopub.status.busy": "2024-11-25T12:48:47.806258Z",
     "iopub.status.idle": "2024-11-25T12:48:47.809228Z",
     "shell.execute_reply": "2024-11-25T12:48:47.808534Z"
    },
    "papermill": {
     "duration": 0.011786,
     "end_time": "2024-11-25T12:48:47.810774",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.798988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del train_dataset\n",
    "# del val_dataset\n",
    "# del test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7454ec0d",
   "metadata": {
    "papermill": {
     "duration": 0.006382,
     "end_time": "2024-11-25T12:48:47.823876",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.817494",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28346525",
   "metadata": {
    "papermill": {
     "duration": 0.006445,
     "end_time": "2024-11-25T12:48:47.836975",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.830530",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Define Dice loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cf8a316c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:47.851854Z",
     "iopub.status.busy": "2024-11-25T12:48:47.851287Z",
     "iopub.status.idle": "2024-11-25T12:48:51.794131Z",
     "shell.execute_reply": "2024-11-25T12:48:51.793301Z"
    },
    "papermill": {
     "duration": 3.952146,
     "end_time": "2024-11-25T12:48:51.795900",
     "exception": false,
     "start_time": "2024-11-25T12:48:47.843754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mtu7pham7\u001b[0m (\u001b[33mhustcollab\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.18.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/kaggle/working/wandb/run-20241125_124848-201yz83a\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mgolden-pine-72\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: â­ï¸ View project at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ðŸš€ View run at \u001b[34m\u001b[4mhttps://wandb.ai/hustcollab/PolypSegment/runs/201yz83a\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(\n",
    "    # set the wandb project where this run will be logged\n",
    "#     project= \"PolypSegment\", \n",
    "    key = \"e02f7703b40a2b3e0ab4801d4cb1d86b3b7327a6\",\n",
    ")\n",
    "\n",
    "wandb.init(\n",
    "    project=\"PolypSegment\",\n",
    "    config={\n",
    "        \"backbone\" : \"resnet50\",\n",
    "        \"init_learning_rate\": learning_rate,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"optimizer\": \"Adam\",\n",
    "        \"loss_functions\": [\"CrossEntropy\", \"Dice\"],\n",
    "        \"alpha\":alpha,\n",
    "        \"imsize\": img_resize\n",
    "    }\n",
    ")\n",
    "\n",
    "# Add the model to WandB\n",
    "wandb.watch(model, log=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2afb7b19",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:51.812618Z",
     "iopub.status.busy": "2024-11-25T12:48:51.812080Z",
     "iopub.status.idle": "2024-11-25T12:48:52.049231Z",
     "shell.execute_reply": "2024-11-25T12:48:52.048231Z"
    },
    "papermill": {
     "duration": 0.247498,
     "end_time": "2024-11-25T12:48:52.051310",
     "exception": false,
     "start_time": "2024-11-25T12:48:51.803812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "model.to(device)\n",
    "criterion_ce = nn.CrossEntropyLoss(weight = torch.tensor(class_weights).to(device))\n",
    "criterion_dice = smp.losses.DiceLoss(mode='multiclass')\n",
    "best_val_loss = 999"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904c8834",
   "metadata": {
    "papermill": {
     "duration": 0.007424,
     "end_time": "2024-11-25T12:48:52.066736",
     "exception": false,
     "start_time": "2024-11-25T12:48:52.059312",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Make use of learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9db15db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:52.082584Z",
     "iopub.status.busy": "2024-11-25T12:48:52.082300Z",
     "iopub.status.idle": "2024-11-25T12:48:52.090607Z",
     "shell.execute_reply": "2024-11-25T12:48:52.089702Z"
    },
    "papermill": {
     "duration": 0.018007,
     "end_time": "2024-11-25T12:48:52.092149",
     "exception": false,
     "start_time": "2024-11-25T12:48:52.074142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "scaler = GradScaler()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Initialize the scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min',                 # We want to minimize the validation loss\n",
    "    factor=0.5,                 # Reduce LR by a factor of 0.5\n",
    "    patience=1,                 # Number of epochs with no improvement after which LR will be reduced\n",
    "    verbose=True,               # Print a message when LR is updated\n",
    "    threshold=0.0001,           # Threshold for measuring the new optimum\n",
    "    threshold_mode='rel',       # Mode for threshold\n",
    "    cooldown=0,                 # Number of epochs to wait before resuming normal operation after LR has been reduced\n",
    "    min_lr=1e-6                 # Lower bound on the learning rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2064379e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:48:52.109158Z",
     "iopub.status.busy": "2024-11-25T12:48:52.108938Z",
     "iopub.status.idle": "2024-11-25T12:57:25.034820Z",
     "shell.execute_reply": "2024-11-25T12:57:25.033904Z"
    },
    "papermill": {
     "duration": 512.946461,
     "end_time": "2024-11-25T12:57:25.046580",
     "exception": false,
     "start_time": "2024-11-25T12:48:52.100119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 1.3125747953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  10%|â–ˆ         | 1/10 [01:02<09:19, 62.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/10], Loss: 0.6203429358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  20%|â–ˆâ–ˆ        | 2/10 [01:52<07:21, 55.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/10], Loss: 0.4499245882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 4/10 [03:32<05:10, 51.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/10], Loss: 0.9639045341\n",
      "Epoch [5/10], Loss: 0.3438253009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 6/10 [05:13<03:22, 50.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/10], Loss: 0.3938963882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 7/10 [06:02<02:30, 50.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/10], Loss: 0.4113145896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 8/10 [06:52<01:40, 50.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Loss: 0.3845239835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 9/10 [07:42<00:50, 50.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/10], Loss: 0.3687370462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Total Progress: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [08:32<00:00, 51.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/10], Loss: 0.3501284782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "epoch_bar = tqdm(total=num_epochs, desc='Total Progress')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_dice = criterion_dice(outputs, labels)\n",
    "            loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        optimizer.zero_grad()\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(dim=1).long()\n",
    "            \n",
    "            with autocast(device_type=\"cuda\"):\n",
    "                outputs = model(images)\n",
    "                loss_ce = criterion_ce(outputs, labels)\n",
    "                loss_dice = criterion_dice(outputs, labels)\n",
    "                loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "\n",
    "            val_loss += loss.item()\n",
    "            \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {val_loss/len(val_loader):.10f}\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        checkpoint = { \n",
    "            'epoch': epoch,\n",
    "            'model': model.state_dict(),\n",
    "            'optimizer': optimizer.state_dict(),\n",
    "            'loss': val_loss,\n",
    "        }\n",
    "        save_path = f'model.pth'\n",
    "        torch.save(checkpoint, save_path)\n",
    "        \n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    epoch_bar.update(1)\n",
    "    wandb.log({'Val_loss': val_loss/len(val_loader),'Train_loss': train_loss/len(train_loader), 'Learning_rate' : current_lr})\n",
    "epoch_bar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5148b1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:25.065319Z",
     "iopub.status.busy": "2024-11-25T12:57:25.064961Z",
     "iopub.status.idle": "2024-11-25T12:57:25.468197Z",
     "shell.execute_reply": "2024-11-25T12:57:25.467240Z"
    },
    "papermill": {
     "duration": 0.415512,
     "end_time": "2024-11-25T12:57:25.470713",
     "exception": false,
     "start_time": "2024-11-25T12:57:25.055201",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4093892069.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load('/kaggle/working/model.pth')\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('/kaggle/working/model.pth')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "90e4eb61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:25.490529Z",
     "iopub.status.busy": "2024-11-25T12:57:25.490243Z",
     "iopub.status.idle": "2024-11-25T12:57:32.508968Z",
     "shell.execute_reply": "2024-11-25T12:57:32.508050Z"
    },
    "papermill": {
     "duration": 7.030582,
     "end_time": "2024-11-25T12:57:32.511126",
     "exception": false,
     "start_time": "2024-11-25T12:57:25.480544",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3122277557849884\n",
      "0.3577023148536682\n",
      "0.3612051010131836\n",
      "0.3526296019554138\n",
      "0.25916826725006104\n",
      "0.3100471496582031\n",
      "0.06631346791982651\n",
      "Loss: 0.2884705226\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.squeeze(dim=1).long()\n",
    "        \n",
    "        with autocast(device_type=\"cuda\"):\n",
    "            outputs = model(images)\n",
    "            # loss_ce = criterion_ce(outputs, labels)\n",
    "            loss_dice = criterion_dice(outputs, labels)\n",
    "            # loss = alpha * loss_ce + (1 - alpha) * loss_dice\n",
    "            print(loss_dice.item())\n",
    "        val_loss += loss_dice.item()\n",
    "print(f\"Loss: {val_loss/len(val_loader):.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6c59fe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:32.536895Z",
     "iopub.status.busy": "2024-11-25T12:57:32.536612Z",
     "iopub.status.idle": "2024-11-25T12:57:33.566047Z",
     "shell.execute_reply": "2024-11-25T12:57:33.564801Z"
    },
    "papermill": {
     "duration": 1.043271,
     "end_time": "2024-11-25T12:57:33.568089",
     "exception": false,
     "start_time": "2024-11-25T12:57:32.524818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606a0951",
   "metadata": {
    "papermill": {
     "duration": 0.008844,
     "end_time": "2024-11-25T12:57:33.586402",
     "exception": false,
     "start_time": "2024-11-25T12:57:33.577558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Get Testset Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "87a944d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:33.605432Z",
     "iopub.status.busy": "2024-11-25T12:57:33.605081Z",
     "iopub.status.idle": "2024-11-25T12:57:33.611198Z",
     "shell.execute_reply": "2024-11-25T12:57:33.610378Z"
    },
    "papermill": {
     "duration": 0.017695,
     "end_time": "2024-11-25T12:57:33.612927",
     "exception": false,
     "start_time": "2024-11-25T12:57:33.595232",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def Smoothed_img(image):\n",
    "    resized_image = image\n",
    "    smoothed_image = cv2.GaussianBlur(resized_image, (15, 15), 0)\n",
    "    red_pixels = (smoothed_image[:, :, 2] > 100)\n",
    "    green_pixels = (smoothed_image[:, :, 1] > 100)\n",
    "    black_pixels = ~(red_pixels | green_pixels)\n",
    "    smoothed_image[red_pixels] = [0, 0, 255]\n",
    "    smoothed_image[green_pixels] = [0, 255, 0]\n",
    "    smoothed_image[black_pixels] = [0, 0, 0]\n",
    "\n",
    "    # pixel_values = np.array(smoothed_image)\n",
    "    # unique_values = np.unique(pixel_values)\n",
    "    # print(unique_values)\n",
    "    return smoothed_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51555d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:33.632475Z",
     "iopub.status.busy": "2024-11-25T12:57:33.632211Z",
     "iopub.status.idle": "2024-11-25T12:57:56.948792Z",
     "shell.execute_reply": "2024-11-25T12:57:56.947819Z"
    },
    "papermill": {
     "duration": 23.328565,
     "end_time": "2024-11-25T12:57:56.950914",
     "exception": false,
     "start_time": "2024-11-25T12:57:33.622349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for image, h, w, name in test_loader:\n",
    "        outputs = model(image.to(device))\n",
    "        outputs = outputs.squeeze().cpu().numpy()\n",
    "        outputs = np.argmax(outputs, axis=0)\n",
    "        outputs = mask_to_rgb(outputs, color_dict)\n",
    "        w = w.item()\n",
    "        h = h.item()\n",
    "        new_size = (w, h)\n",
    "        resized_image = cv2.resize(outputs, new_size, interpolation=cv2.INTER_CUBIC)\n",
    "        resized_image = cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = Smoothed_img(resized_image)\n",
    "        cv2.imwrite(f\"prediction/{name[0]}.png\", resized_image)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9e575523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-25T12:57:56.972522Z",
     "iopub.status.busy": "2024-11-25T12:57:56.972148Z",
     "iopub.status.idle": "2024-11-25T12:58:00.012848Z",
     "shell.execute_reply": "2024-11-25T12:58:00.011921Z"
    },
    "papermill": {
     "duration": 3.054506,
     "end_time": "2024-11-25T12:58:00.014955",
     "exception": false,
     "start_time": "2024-11-25T12:57:56.960449",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def rle_to_string(runs):\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle_encode_one_mask(mask):\n",
    "    pixels = mask.flatten()\n",
    "    pixels[pixels > 225] = 255\n",
    "    pixels[pixels <= 225] = 0\n",
    "    use_padding = False\n",
    "    if pixels[0] or pixels[-1]:\n",
    "        use_padding = True\n",
    "        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n",
    "        pixel_padded[1:-1] = pixels\n",
    "        pixels = pixel_padded\n",
    "    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n",
    "    if use_padding:\n",
    "        rle = rle - 1\n",
    "    rle[1::2] = rle[1::2] - rle[:-1:2]\n",
    "    \n",
    "    return rle_to_string(rle)\n",
    "\n",
    "def rle2mask(mask_rle, shape=(3,3)):\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 1\n",
    "    return img.reshape(shape).T\n",
    "\n",
    "def mask2string(dir):\n",
    "    strings = []\n",
    "    ids = []\n",
    "    ws, hs = [[] for i in range(2)]\n",
    "    for image_id in os.listdir(dir):\n",
    "        id = image_id.split('.')[0]\n",
    "        path = os.path.join(dir, image_id)\n",
    "        # print(path)\n",
    "        img = cv2.imread(path)[:,:,::-1]\n",
    "        h, w = img.shape[0], img.shape[1]\n",
    "        for channel in range(2):\n",
    "            ws.append(w)\n",
    "            hs.append(h)\n",
    "            ids.append(f'{id}_{channel}')\n",
    "            string = rle_encode_one_mask(img[:,:,channel])\n",
    "            strings.append(string)\n",
    "    r = {\n",
    "        'ids': ids,\n",
    "        'strings': strings,\n",
    "    }\n",
    "    return r\n",
    "\n",
    "\n",
    "MASK_DIR_PATH = '/kaggle/working/prediction'\n",
    "dir = MASK_DIR_PATH\n",
    "res = mask2string(dir)\n",
    "df = pd.DataFrame(columns=['Id', 'Expected'])\n",
    "df['Id'] = res['ids']\n",
    "df['Expected'] = res['strings']\n",
    "\n",
    "df.to_csv(r'output.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 2715462,
     "sourceId": 30892,
     "sourceType": "competition"
    },
    {
     "datasetId": 6156191,
     "sourceId": 10001462,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 585.518398,
   "end_time": "2024-11-25T12:58:02.742205",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-11-25T12:48:17.223807",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
